https://leetcode.com/explore/learn/card/graph/623/kahns-algorithm-for-topological-sorting/3954/

### Types of Graphs

Graphs are mathematical structures used to model pairwise relations between objects. There are several types of graphs, each with unique characteristics. In this card, we will introduce three types of graphs: undirected graphs, directed graphs, and weighted graphs.

#### Undirected Graphs
In an undirected graph, the edges between any two vertices do not have a direction, indicating a two-way relationship. This means that if there is an edge between vertex A and vertex B, you can traverse from A to B and from B to A with equal ease.

**Figure 1:** An example of an undirected graph.

```
   A — B
   |   |
   D — C
```

#### Directed Graphs
In a directed graph, also known as a digraph, the edges between vertices have a direction. This indicates a one-way relationship where traversal is allowed only in the direction specified by the edge.

**Figure 2:** An example of a directed graph.

```
   A → B
   ↓   ↓
   D ← C
```

#### Weighted Graphs
In a weighted graph, each edge has an associated weight. The weight can represent various metrics such as time, distance, or cost. This type of graph is commonly used in scenarios like city maps where each edge (road) has a distance (weight).

**Figure 3:** An example of a weighted graph.

```
   A -5- B
   |     |
  2|     |3
   D -1- C
```

In this example, the numbers on the edges represent the weights, such as distances between the vertices.

### Summary
- **Undirected Graphs:** Edges indicate a bidirectional relationship.
- **Directed Graphs:** Edges indicate a unidirectional relationship.
- **Weighted Graphs:** Edges have weights representing metrics like distance or cost. 

Understanding these different types of graphs is crucial in various fields such as computer science, transportation, and network analysis.

### 图的定义和术语

“图”（Graph）是一种非线性数据结构，由顶点和边组成。在描述图时，有许多术语需要了解。如果在以下探讨卡片中遇到不熟悉的术语，可以查阅下面的定义。

#### 顶点（Vertex）
在图中，像A、B和C这样的节点被称为顶点（Vertices）。顶点是图的基本单元，每个顶点可以代表一个对象或位置。在图的表示中，顶点通常用圆圈或点来表示。

#### 边（Edge）
顶点之间的连接称为边（Edges）。在图中，边表示两个顶点之间的关系或连接。在图1中，顶点A和B之间的连接就是一条边。边可以是有方向的（表示单向关系）或无方向的（表示双向关系）。

#### 路径（Path）
路径是指从一个顶点到另一个顶点经过的顶点序列。在图1中，从A到C的路径可以是[A, B, C]，也可以是[A, G, B, C]，或者[A, E, F, D, B, C]。需要注意的是，两顶点之间可以有多条路径。

#### 路径长度（Path Length）
路径长度是指路径中边的数量。在图1中，从A到C的路径长度分别为2、3和5。路径长度是评估路径复杂度和效率的重要指标。

#### 环（Cycle）
环是指起点和终点为同一个顶点的路径。在图1中，[A, B, D, F, E]构成了一个环，同样，[A, G, B]也构成了另一个环。环在图论中有重要的应用，如检测死锁和循环依赖。

#### 负权环（Negative Weight Cycle）
在加权图中，如果一个环的所有边的权重之和为负值，则称其为负权环。在图4中，权重之和为-3的环就是一个负权环。负权环在某些算法中会导致问题，如最短路径问题。

#### 连接性（Connectivity）
如果两个顶点之间至少存在一条路径，这两个顶点就是连接的。在图1中，A和C是连接的，因为至少有一条路径将它们连接起来。连接性是图的一个基本性质，用于判断图的整体结构。

#### 顶点的度（Degree of a Vertex）
度是指与一个顶点相连接的边的数量。在无权图中使用该术语。在图1中，顶点A的度为3，因为有三条边与其相连。顶点的度在分析图的局部结构时非常有用。

#### 入度（In-Degree）
入度是有向图中的概念。如果一个顶点的入度为d，表示有d条方向性的边指向该顶点。在图2中，顶点A的入度为1，即从F到A的一条边。

#### 出度（Out-Degree）
出度是有向图中的概念。如果一个顶点的出度为d，表示有d条边从该顶点指向其他顶点。在图2中，顶点A的出度为3，即从A到B、A到C和A到G的三条边。

这些术语构成了理解图和图论的基础，通过掌握这些概念，可以更好地应用图论在计算机科学、网络分析和许多其他领域。

### 给定顶点和它们之间的边，如何快速检查两个顶点是否连通？
例如，图5展示了顶点之间的边，那么我们如何高效地检查0是否与3连接，1是否与5连接，或者7是否与8连接？我们可以使用“互斥集”数据结构，也称为“并查集”数据结构来实现。注意，有些人可能会将其称为一种算法。在这张探讨卡片中，术语“互斥集”指的是一种数据结构。

#### 图5：每个图由顶点和边组成。蓝色的顶点为根顶点。

互斥集的主要用途是解决网络组件之间的连通性问题。这里的“网络”可以是计算机网络或社交网络。例如，我们可以使用互斥集来确定两个人是否有共同的祖先。

#### 术语
- **父节点（Parent node）**：一个顶点的直接父节点。例如，在图5中，顶点3的父节点是1，顶点2的父节点是0，顶点9的父节点是9。
- **根节点（Root node）**：没有父节点的节点；它可以被视为它自己的父节点。例如，在图5中，顶点3和2的根节点是0。而对于0来说，它既是自己的根节点，也是自己的父节点。同样，顶点9的根节点和父节点都是它自己。有时根节点也被称为头节点（head node）。

### 互斥集简介

#### 互斥集是如何工作的
互斥集通过两个主要操作来解决连通性问题：查找（Find）和合并（Union）。查找操作用于找到给定顶点的根节点，而合并操作用于将两个顶点的根节点统一。

#### 实现互斥集
实现互斥集的数据结构主要有两种方法：快速查找（Quick Find）和快速合并（Quick Union）。这两种方法的时间复杂度有所不同。

#### 互斥集的两个重要函数
- **查找函数（Find）**：查找给定顶点的根节点。例如，在图5中，顶点3的根节点是0。
- **合并函数（Union）**：将两个顶点合并，使它们的根节点相同。例如，在图5中，如果我们将顶点4和顶点5合并，它们的根节点将变为相同，这意味着合并函数会修改顶点4或顶点5的根节点，使其与另一个顶点的根节点相同。

### 互斥集的两种实现方法
- **快速查找实现（Quick Find）**：在这种情况下，查找函数的时间复杂度为O(1)，但合并函数的时间复杂度为O(N)。
- **快速合并实现（Quick Union）**：与快速查找实现相比，合并函数的时间复杂度较好，而查找函数的时间复杂度则更高。

#### 图解示例（Figure 5）
```plaintext
   0    7    8
  / \        |
 1   2       9
  \   |
   3  4
```

在这个例子中：
- **查找（Find）**：顶点3的根节点是0，顶点4的根节点也是0。
- **合并（Union）**：如果我们将顶点4和顶点5合并，它们的根节点将变为相同。

### 结论
互斥集通过高效的查找和合并操作来解决连通性问题，是处理动态连通性问题的有效工具。理解互斥集的工作原理和实现方法对于解决复杂网络问题非常重要。

### 互斥集概述

#### 什么是互斥集？
互斥集（Disjoint Set），也被称为并查集（Union-Find），是一种数据结构，用于管理一些不相交的集合，主要用于解决动态连通性问题。这种数据结构支持两种基本操作：查找（Find）和合并（Union）。

#### 基本概念
互斥集通过一组树来表示集合，每个树的根节点代表该集合的标识。每个节点都指向它的父节点，根节点是指向它自己的节点。以下是一些关键术语：

- **顶点（Vertex）**：图中的节点。
- **边（Edge）**：连接两个顶点的线。
- **父节点（Parent node）**：顶点的直接父节点。
- **根节点（Root node）**：没有父节点的节点，是树的最高节点。

#### 图5示例
```
   0    7    8
  / \        |
 1   2       9
  \   |
   3  4
```
在图5中，顶点3的父节点是1，顶点2的父节点是0，顶点9的父节点是8。

#### 互斥集的主要用途
互斥集的主要用途是处理网络中的连通性问题，这些网络可以是计算机网络、社交网络等。例如，可以用互斥集来确定两个顶点（如两个人）是否在同一个集合中（即是否连通）。

#### 互斥集的两个基本操作
1. **查找（Find）**：查找给定顶点的根节点。例如，在图5中，顶点3的根节点是0。
2. **合并（Union）**：将两个集合合并，使它们的根节点相同。例如，如果将顶点4和顶点5合并，它们的根节点将变为相同。

#### 互斥集的实现方法
- **快速查找（Quick Find）**：查找操作的时间复杂度为O(1)，但合并操作的时间复杂度为O(N)。
- **快速合并（Quick Union）**：合并操作的时间复杂度较好，但查找操作的时间复杂度较高。

### 互斥集的优化策略
为了提高互斥集的效率，可以采用两种常见的优化策略：

1. **路径压缩（Path Compression）**：在查找操作中，将访问路径上的所有节点直接连接到根节点，从而压缩树的高度，优化后续操作的效率。
2. **按秩合并（Union by Rank）**：在合并操作中，总是将高度较小的树连接到高度较大的树上，以保持树的平衡，减少树的高度。

### 总结
互斥集是一种强大的数据结构，广泛应用于解决动态连通性问题。通过查找和合并操作，互斥集可以高效地管理和查询集合之间的连通性。理解其工作原理和实现方法，对于计算机科学和图论的应用非常重要。

### 快速查找（Quick Find）- 互斥集

#### 什么是快速查找（Quick Find）？
快速查找（Quick Find）是实现互斥集（Disjoint Set）的一种方法。在快速查找方法中，每个顶点直接指向它所在集合的根节点，这样可以在常数时间内完成查找操作。然而，合并操作的效率较低。

#### 数据结构
快速查找的核心是一个数组 `id`，其中 `id[i]` 表示顶点 `i` 所在集合的根节点。例如，如果 `id[3] = 0`，则表示顶点3的根节点是0。

#### 初始化
初始化时，每个顶点的根节点是它自己，因此 `id[i] = i` 对于所有顶点 `i` 都成立。

#### 查找操作（Find）
查找操作的时间复杂度为O(1)，因为直接访问数组即可得到结果。例如，要查找顶点 `i` 的根节点，只需返回 `id[i]` 即可。

#### 合并操作（Union）
合并操作的时间复杂度为O(N)，因为需要遍历整个数组，将一个集合的所有元素的根节点更新为另一个集合的根节点。具体步骤如下：
1. 找到两个顶点 `p` 和 `q` 的根节点。
2. 如果根节点不同，则将所有与 `p` 同集合的顶点的根节点更新为 `q` 的根节点。

#### 代码示例
以下是用Python实现的快速查找互斥集的代码：

```python
class QuickFindUF:
    def __init__(self, n):
        # 初始化时，每个顶点的根节点是它自己
        self.id = list(range(n))

    def find(self, p):
        # 查找顶点 p 的根节点
        return self.id[p]

    def union(self, p, q):
        # 找到 p 和 q 的根节点
        pid = self.find(p)
        qid = self.find(q)
        
        # 如果根节点不同，则进行合并
        if pid != qid:
            for i in range(len(self.id)):
                if self.id[i] == pid:
                    self.id[i] = qid

# 示例
uf = QuickFindUF(10)
uf.union(4, 3)
uf.union(3, 8)
uf.union(6, 5)
uf.union(9, 4)
uf.union(2, 1)
print(uf.find(8))  # 输出: 8
print(uf.find(9))  # 输出: 8
print(uf.find(1))  # 输出: 1
```

#### 优缺点
- **优点**：查找操作非常快，时间复杂度为O(1)。
- **缺点**：合并操作较慢，时间复杂度为O(N)，因为需要更新整个数组。

#### 示例图解
假设有以下顶点和边的集合：
```
初始状态：
0   1   2   3   4   5   6   7   8   9
0   1   2   3   4   5   6   7   8   9

合并操作：
union(4, 3) 后：
0   1   2   3   3   5   6   7   8   9
0   1   2   3   3   5   6   7   8   9

union(3, 8) 后：
0   1   2   8   8   5   6   7   8   9
0   1   2   8   8   5   6   7   8   9

union(6, 5) 后：
0   1   2   8   8   5   5   7   8   9
0   1   2   8   8   5   5   7   8   9

查找操作：
find(8) 返回 8
find(9) 返回 9
```

### 总结
快速查找方法适用于需要频繁查找而合并操作较少的情况。尽管合并操作的时间复杂度较高，但查找操作的高效性使其在特定场景中具有优势。了解和掌握快速查找方法，对于优化数据结构和算法性能具有重要意义。

### UnionFind 类

`UnionFind` 类实现了快速查找（Quick Find）互斥集数据结构。这个类包含了初始化、查找、合并和连通性检查等功能。下面是该类的详细解释：

#### 类定义和初始化
```python
class UnionFind:
    def __init__(self, size):
        self.root = [i for i in range(size)]
```
初始化方法 `__init__` 创建了一个大小为 `size` 的数组 `root`，其中 `root[i]` 表示顶点 `i` 所在集合的根节点。初始时，每个顶点的根节点是它自己。

#### 查找函数（Find）
```python
def find(self, x):
    return self.root[x]
```
查找函数 `find` 返回顶点 `x` 的根节点。因为使用了快速查找方法，查找操作的时间复杂度为 O(1)。

#### 合并函数（Union）
```python
def union(self, x, y):
    rootX = self.find(x)
    rootY = self.find(y)
    if rootX != rootY:
        for i in range(len(self.root)):
            if self.root[i] == rootY:
                self.root[i] = rootX
```
合并函数 `union` 将顶点 `x` 和顶点 `y` 所在的集合合并。首先找到 `x` 和 `y` 的根节点，如果它们不同，则遍历整个数组，将 `root` 为 `rootY` 的元素的根节点改为 `rootX`。这样保证了两个集合的所有元素都连接到一起。

#### 连通性检查函数（Connected）
```python
def connected(self, x, y):
    return self.find(x) == self.find(y)
```
连通性检查函数 `connected` 检查顶点 `x` 和顶点 `y` 是否在同一个集合中。通过比较它们的根节点来判断。

### 测试用例
以下是一些测试用例，展示了如何使用 `UnionFind` 类来管理和检查连通性：

```python
# 创建一个有 10 个顶点的 UnionFind 对象
uf = UnionFind(10)
# 建立连接：1-2-5-6-7 和 3-8-9，顶点 4 独立
uf.union(1, 2)
uf.union(2, 5)
uf.union(5, 6)
uf.union(6, 7)
uf.union(3, 8)
uf.union(8, 9)

# 检查连通性
print(uf.connected(1, 5))  # 输出: True
print(uf.connected(5, 7))  # 输出: True
print(uf.connected(4, 9))  # 输出: False

# 合并 9 和 4，使得 3-8-9-4 连通
uf.union(9, 4)
print(uf.connected(4, 9))  # 输出: True
```

### 示例图解
假设我们有以下顶点和边的集合：
```
初始状态：
0   1   2   3   4   5   6   7   8   9
0   1   2   3   4   5   6   7   8   9

合并操作：
union(1, 2) 后：
0   1   1   3   4   5   6   7   8   9
0   1   2   3   4   5   6   7   8   9

union(2, 5) 后：
0   1   1   3   4   1   6   7   8   9
0   1   2   3   4   5   6   7   8   9

union(5, 6) 后：
0   1   1   3   

### 快速合并（Quick Union）- 互斥集实现

#### 复杂度分析

##### 最坏情况分析
在最坏情况下，获取根节点的操作次数将是树的高度 \( H \)。由于这种实现方法并不总是将较矮树的根指向较高树的根，因此 \( H \) 最多可以达到 \( N \)（当树形成一个链表时）。

##### 初始化
与快速查找实现相同，初始化一个 union-find 构造函数时，需要创建一个大小为 \( N \) 的数组，其值等于相应的数组索引。这需要线性时间 \( O(N) \)。

##### 查找操作（Find）
在最坏情况下，查找操作需要遍历每个顶点以找到输入顶点的根节点。获取根节点的最大操作次数不会超过树的高度 \( H \)，因此时间复杂度为 \( O(N) \)。

##### 合并操作（Union）
合并操作由两个查找操作组成，在最坏情况下每个查找操作的时间复杂度为 \( O(N) \)。此外，还包括两个常数时间操作：相等性检查和更新给定索引处的数组值。因此，合并操作在最坏情况下的时间复杂度也是 \( O(N) \)。

##### 连通性检查操作（Connected）
连通性检查操作涉及两个查找操作，在最坏情况下每个查找操作的时间复杂度为 \( O(N) \)。因此，连通性检查操作在最坏情况下的时间复杂度也是 \( O(N) \)。

#### 空间复杂度
Union-Find 数据结构的空间复杂度为 \( O(N) \)，因为我们需要一个大小为 \( N \) 的数组来存储每个顶点的根节点信息。

### 优化策略
为了提高 Union-Find 的效率，可以采用两种常见的优化策略：

1. **路径压缩（Path Compression）**：
   在查找操作中，将访问路径上的所有节点直接连接到根节点，从而压缩树的高度，优化后续操作的效率。
   
2. **按秩合并（Union by Rank）**：
   在合并操作中，总是将高度较小的树连接到高度较大的树上，以保持树的平衡，减少树的高度。

### 完整代码示例（包含路径压缩和按秩合并的实现）

```python
class UnionFind:
    def __init__(self, size):
        self.root = [i for i in range(size)]
        self.rank = [1] * size

    def find(self, x):
        if x != self.root[x]:
            self.root[x] = self.find(self.root[x])  # 路径压缩
        return self.root[x]
		
    def union(self, x, y):
        rootX = self.find(x)
        rootY = self.find(y)
        if rootX != rootY:
            # 按秩合并
            if self.rank[rootX] > self.rank[rootY]:
                self.root[rootY] = rootX
            elif self.rank[rootX] < self.rank[rootY]:
                self.root[rootX] = rootY
            else:
                self.root[rootY] = rootX
                self.rank[rootX] += 1

    def connected(self, x, y):
        return self.find(x) == self.find(y)

# 测试用例
uf = UnionFind(10)
# 1-2-5-6-7 3-8-9 4
uf.union(1, 2)
uf.union(2, 5)
uf.union(5, 6)
uf.union(6, 7)
uf.union(3, 8)
uf.union(8, 9)
print(uf.connected(1, 5))  # 输出: True
print(uf.connected(5, 7))  # 输出: True
print(uf.connected(4, 9))  # 输出: False
# 1-2-5-6-7 3-8-9-4
uf.union(9, 4)
print(uf.connected(4, 9))  # 输出: True
```

### 解释与示例
1. **路径压缩**：
   在每次查找时，将当前节点直接连接到根节点。这样可以大大减少树的高度，提高后续查找操作的效率。

2. **按秩合并**：
   在合并操作中，总是将较矮树的根节点指向较高树的根节点，以保持树的平衡。这样可以避免树变得过高，从而提高查找操作的效率。

使用路径压缩和按秩合并后的 Union-Find 数据结构在最坏情况下的时间复杂度接近常数时间 \( O(\alpha(N)) \)，其中 \( \alpha \) 是阿克曼函数的逆函数，在实际应用中增长非常缓慢。
### 路径压缩优化 - 互斥集

#### 什么是路径压缩（Path Compression）？
路径压缩是一种在执行查找（Find）操作时优化树结构的技术。其核心思想是在查找根节点的过程中，将访问路径上的所有节点直接连接到根节点，从而压缩树的高度。这种优化可以显著提高后续查找操作的效率，使查找操作的时间复杂度接近常数时间 \( O(\alpha(N)) \)，其中 \( \alpha \) 是阿克曼函数的逆函数，在实际应用中增长非常缓慢。

#### 路径压缩的实现
在实现路径压缩的 `find` 方法中，如果当前节点 `x` 不是根节点，则递归查找其父节点，直到找到根节点。在递归返回时，将路径上的所有节点直接连接到根节点。

#### 代码示例

以下是使用路径压缩优化后的 Union-Find 类的完整代码：

```python
class UnionFind:
    def __init__(self, size):
        self.root = [i for i in range(size)]

    def find(self, x):
        if x != self.root[x]:
            self.root[x] = self.find(self.root[x])  # 路径压缩
        return self.root[x]
		
    def union(self, x, y):
        rootX = self.find(x)
        rootY = self.find(y)
        if rootX != rootY:
            self.root[rootY] = rootX

    def connected(self, x, y):
        return self.find(x) == self.find(y)

# 测试用例
uf = UnionFind(10)
# 建立连接：1-2-5-6-7 和 3-8-9，顶点 4 独立
uf.union(1, 2)
uf.union(2, 5)
uf.union(5, 6)
uf.union(6, 7)
uf.union(3, 8)
uf.union(8, 9)

# 检查连通性
print(uf.connected(1, 5))  # 输出: True
print(uf.connected(5, 7))  # 输出: True
print(uf.connected(4, 9))  # 输出: False

# 合并 9 和 4，使得 3-8-9-4 连通
uf.union(9, 4)
print(uf.connected(4, 9))  # 输出: True
```

### 解释与示例

#### 初始状态
假设我们有以下顶点和边的集合，初始时每个顶点的根节点是它自己：
```
初始状态：
0   1   2   3   4   5   6   7   8   9
0   1   2   3   4   5   6   7   8   9
```

#### 合并操作
执行一些合并操作：
```python
uf.union(1, 2)
uf.union(2, 

Number of Provinces
Solution
There are n cities. Some of them are connected, while some are not. If city a is connected directly with city b, and city b is connected directly with city c, then city a is connected indirectly with city c.
A province is a group of directly or indirectly connected cities and no other cities outside of the group.
You are given an n x n matrix isConnected where isConnected[i][j] = 1 if the ith city and the jth city are directly connected, and isConnected[i][j] = 0 otherwise.
Return the total number of provinces.


### 优化的互斥集 - 路径压缩和按秩合并

为了进一步优化 Union-Find 数据结构，我们可以结合路径压缩（Path Compression）和按秩合并（Union by Rank）。这种组合优化可以显著提高查找和合并操作的效率，使得这些操作在最坏情况下的时间复杂度接近常数时间 \( O(\alpha(N)) \)，其中 \( \alpha \) 是阿克曼函数的逆函数。

#### 路径压缩（Path Compression）
在执行查找（Find）操作时，将访问路径上的所有节点直接连接到根节点，从而压缩树的高度。

#### 按秩合并（Union by Rank）
在执行合并（Union）操作时，总是将较矮树的根节点指向较高树的根节点，以保持树的平衡，减少树的高度。

#### 优化后的代码实现

以下是结合路径压缩和按秩合并的 Union-Find 类的完整代码：

```python
class UnionFind:
    def __init__(self, size):
        self.root = [i for i in range(size)]
        self.rank = [1] * size  # 初始化每个顶点的秩为1

    def find(self, x):
        if x != self.root[x]:
            self.root[x] = self.find(self.root[x])  # 路径压缩
        return self.root[x]

    def union(self, x, y):
        rootX = self.find(x)
        rootY = self.find(y)

        if rootX != rootY:
            # 按秩合并
            if self.rank[rootX] > self.rank[rootY]:
                self.root[rootY] = rootX
            elif self.rank[rootX] < self.rank[rootY]:
                self.root[rootX] = rootY
            else:
                self.root[rootY] = rootX
                self.rank[rootX] += 1

    def connected(self, x, y):
        return self.find(x) == self.find(y)

# 测试用例
uf = UnionFind(10)
# 建立连接：1-2-5-6-7 和 3-8-9，顶点 4 独立
uf.union(1, 2)
uf.union(2, 5)
uf.union(5, 6)
uf.union(6, 7)
uf.union(3, 8)
uf.union(8, 9)

# 检查连通性
print(uf.connected(1, 5))  # 输出: True
print(uf.connected(5, 7))  # 输出: True
print(uf.connected(4, 9))  # 输出: False

# 合并 9 和 4，使得 3-8-9-4 连通
uf.union(9, 4)
print(uf.connected(4, 9))  # 输出: True
```

### 解释与示例

#### 初始状态
假设我们有以下顶点和边的集合，初始时每个顶点的根节点是它自己，并且每个顶点的秩为1：
```
初始状态：
0   1   2   3   4   5   6   7   8   9
0   1   2   3   4   5   6   7   8   9
秩：
1   1   1   1   1   1   1   1   1   1
```

#### 合并操作
执行一些合并操作：

1. `uf.union(1, 2)`
```
根节点：
0   1   1   3   4   5   6   7   8   9
0   1   2   3   4   5   6   7   8   9
秩：
1   2   1   1   1   1   1   1   1   1
```

2. `uf.union(2, 5)`
```
根节点：
0   1   1   3   4   1   6   7   8   9
0   1   2   3   4   5   6   7   8   9
秩：
1   2   1   1   1   1   1   1   1   1
```

3. `uf.union(5, 6)`
```
根节点：
0   1   1   3   4   1   1   7   8   9
0   1   2   3   4   5   6   7   8   9
秩：
1   2   1   1   1   1   1   1   1   1
```

4. `uf.union(6, 7)`
```
根节点：
0   1   1   3   4   1   1   1   8   9
0   1   2   3   4   5   6   7   8   9
秩：
1   2   1   1   1   1   1   1   1   1
```

5. `uf.union(3, 8)`
```
根节点：
0   1   1   3   4   1   1   1   3   9
0   1   2   3   4   5   6   7   8   9
秩：
1   2   1   1   1   1   1   1   2   1
```

6. `uf.union(8, 9)`
```
根节点：
0   1   1   3   4   1   1   1   3   3
0   1   2   3   4   5   6   7   8   9
秩：
1   2   1   1   1   1   1   1   2   1
```

### 结论
通过结合路径压缩和按秩合并，Union-Find 数据结构能够更高效地管理和查询集合之间的连通性。这种优化使得查找和合并操作在实际应用中的时间复杂度接近常数时间 \( O(\alpha(N)) \)。这种高效的数据结构广泛应用于解决动态连通性问题，如网络连接和图论问题。

To solve the problem of finding the number of provinces, we can use the Union-Find (Disjoint Set) data structure. Provinces are groups of directly or indirectly connected cities, and the Union-Find data structure helps us efficiently manage and find connected components.

Here's a step-by-step solution using Union-Find with Path Compression and Union by Rank optimizations:

1. **Initialize the Union-Find structure**: Each city starts in its own province.
2. **Process the isConnected matrix**: For each pair of cities that are directly connected, union their sets.
3. **Count distinct root nodes**: The number of unique root nodes after processing the matrix will be the number of provinces.

### Union-Find Class with Path Compression and Union by Rank

```python
class UnionFind:
    def __init__(self, size):
        self.root = [i for i in range(size)]
        self.rank = [1] * size  # Initialize rank for union by rank

    def find(self, x):
        if x != self.root[x]:
            self.root[x] = self.find(self.root[x])  # Path compression
        return self.root[x]

    def union(self, x, y):
        rootX = self.find(x)
        rootY = self.find(y)

        if rootX != rootY:
            # Union by rank
            if self.rank[rootX] > self.rank[rootY]:
                self.root[rootY] = rootX
            elif self.rank[rootX] < self.rank[rootY]:
                self.root[rootX] = rootY
            else:
                self.root[rootY] = rootX
                self.rank[rootX] += 1

    def connected(self, x, y):
        return self.find(x) == self.find(y)
    
    def count_provinces(self):
        return len(set(self.find(x) for x in range(len(self.root))))

def findCircleNum(isConnected):
    n = len(isConnected)
    uf = UnionFind(n)

    for i in range(n):
        for j in range(i + 1, n):
            if isConnected[i][j] == 1:
                uf.union(i, j)
    
    return uf.count_provinces()

# Test case
isConnected = [
    [1, 1, 0],
    [1, 1, 0],
    [0, 0, 1]
]

print(findCircleNum(isConnected))  # Output: 2
```

### Explanation
1. **UnionFind Class**:
   - `__init__`: Initializes the root and rank arrays.
   - `find`: Uses path compression to find the root of a node.
   - `union`: Unions two sets by rank, ensuring the smaller tree is always attached under the larger tree.
   - `connected`: Checks if two nodes are in the same set.
   - `count_provinces`: Counts the number of unique provinces by counting unique root nodes.

2. **findCircleNum Function**:
   - Initializes a UnionFind instance for `n` cities.
   - Processes the `isConnected` matrix to union cities that are directly connected.
   - Returns the number of provinces by counting unique root nodes.

### Test Case
The provided test case:
```python
isConnected = [
    [1, 1, 0],
    [1, 1, 0],
    [0, 0, 1]
]
```
The output is `2`, indicating there are two provinces: one consisting of cities 0 and 1, and another consisting of city 2.

To determine whether a given graph with `n` nodes and a list of edges forms a valid tree, we need to check two main properties:

1. **A tree must be connected**: All nodes must be reachable from any other node.
2. **A tree must be acyclic**: There should be no cycles in the graph.

Given that the graph is undirected, we can utilize the Union-Find (Disjoint Set) data structure to efficiently manage connectivity and check for cycles. Here's a step-by-step solution using Union-Find:

### Steps to Solve

1. **Check the Number of Edges**: For a graph to be a tree, it must have exactly `n-1` edges.
2. **Use Union-Find to Detect Cycles**: As we process each edge, if we find that two nodes are already in the same set, it indicates a cycle.

### Union-Find Implementation with Cycle Detection

```python
class UnionFind:
    def __init__(self, size):
        self.root = [i for i in range(size)]
        self.rank = [1] * size  # Initialize rank for union by rank

    def find(self, x):
        if x != self.root[x]:
            self.root[x] = self.find(self.root[x])  # Path compression
        return self.root[x]

    def union(self, x, y):
        rootX = self.find(x)
        rootY = self.find(y)

        if rootX != rootY:
            # Union by rank
            if self.rank[rootX] > self.rank[rootY]:
                self.root[rootY] = rootX
            elif self.rank[rootX] < self.rank[rootY]:
                self.root[rootX] = rootY
            else:
                self.root[rootY] = rootX
                self.rank[rootX] += 1
            return True
        return False  # If rootX == rootY, a cycle is detected

def validTree(n, edges):
    if len(edges) != n - 1:
        return False  # A tree must have exactly n - 1 edges
    
    uf = UnionFind(n)

    for edge in edges:
        if not uf.union(edge[0], edge[1]):
            return False  # Cycle detected
    
    return True  # No cycles detected, and the number of edges is n - 1

# Test case
n = 5
edges = [
    [0, 1],
    [0, 2],
    [0, 3],
    [1, 4]
]

print(validTree(n, edges))  # Output: True
```

### Explanation

1. **Initialization**:
   - The `UnionFind` class initializes the root and rank arrays to manage the union-find operations with path compression and union by rank optimizations.

2. **Union-Find Operations**:
   - The `find` function finds the root of a node with path compression.
   - The `union` function unites two sets by rank and checks if they are already in the same set to detect cycles. It returns `False` if a cycle is detected (i.e., both nodes have the same root).

3. **Valid Tree Check**:
   - First, we check if the number of edges is exactly `n-1`. If not, it cannot be a tree.
   - Then, we process each edge with the union operation. If any union operation returns `False`, it indicates a cycle, and the graph is not a tree.
   - If all edges are processed without detecting a cycle and the number of edges is `n-1`, the graph is a valid tree.

### Test Case

The provided test case:
```python
n = 5
edges = [
    [0, 1],
    [0, 2],
    [0, 3],
    [1, 4]
]
```
The output is `True`, indicating that the graph forms a valid tree.

To find the number of connected components in an undirected graph, we can use the Union-Find (Disjoint Set) data structure. This allows us to efficiently manage and find the connected components by uniting nodes that are directly connected by edges.

Here's a step-by-step solution using Union-Find:

### Steps to Solve

1. **Initialize the Union-Find structure**: Each node starts as its own component.
2. **Process the edges**: For each edge, unite the two nodes it connects.
3. **Count the distinct root nodes**: The number of unique root nodes represents the number of connected components.

### Union-Find Implementation

Here's the Python code implementing the solution using Union-Find:

```python
class UnionFind:
    def __init__(self, size):
        self.root = [i for i in range(size)]
        self.rank = [1] * size  # Initialize rank for union by rank

    def find(self, x):
        if x != self.root[x]:
            self.root[x] = self.find(self.root[x])  # Path compression
        return self.root[x]

    def union(self, x, y):
        rootX = self.find(x)
        rootY = self.find(y)

        if rootX != rootY:
            # Union by rank
            if self.rank[rootX] > self.rank[rootY]:
                self.root[rootY] = rootX
            elif self.rank[rootX] < self.rank[rootY]:
                self.root[rootX] = rootY
            else:
                self.root[rootY] = rootX
                self.rank[rootX] += 1

    def count_components(self):
        # Count unique root nodes
        return len(set(self.find(x) for x in range(len(self.root))))

def countComponents(n, edges):
    uf = UnionFind(n)

    for edge in edges:
        uf.union(edge[0], edge[1])

    return uf.count_components()

# Test case
n = 5
edges = [
    [0, 1],
    [1, 2],
    [3, 4]
]

print(countComponents(n, edges))  # Output: 2
```

### Explanation

1. **UnionFind Class**:
   - `__init__`: Initializes the root and rank arrays.
   - `find`: Uses path compression to find the root of a node, making the tree flat and speeding up future operations.
   - `union`: Unites two sets by rank, ensuring the smaller tree is always attached under the larger tree.
   - `count_components`: Counts the number of unique root nodes, representing the number of connected components.

2. **countComponents Function**:
   - Initializes a UnionFind instance for `n` nodes.
   - Processes each edge by uniting the two nodes it connects.
   - Returns the number of connected components by counting the unique root nodes.

### Test Case

The provided test case:
```python
n = 5
edges = [
    [0, 1],
    [1, 2],
    [3, 4]
]
```
The output is `2`, indicating that there are two connected components in the graph:
- Component 1: Nodes 0, 1, and 2
- Component 2: Nodes 3 and 4

This solution is efficient with a time complexity close to \( O(\alpha(N)) \), where \( \alpha \) is the inverse Ackermann function, and a space complexity of \( O(N) \).


### 最小生成树概述

#### 什么是最小生成树（Minimum Spanning Tree，MST）？
最小生成树（MST）是图论中的一个概念。对于一个连通的加权无向图，最小生成树是该图的一个子图，它包含了图中的所有顶点，并且使得所有边的权重之和最小，同时保证没有环路。换句话说，最小生成树是连接所有顶点的边权重和最小的树。

#### 最小生成树的应用
最小生成树在许多实际问题中有广泛应用，包括：
- 网络设计：如计算机网络、道路网络、管道网络的设计，目标是以最小的成本连接所有节点。
- 聚类分析：在数据聚类中，MST可用于构建层次聚类。
- 机器人路径规划：MST可用于寻找连接所有点的最短路径。

#### 经典算法
有几种经典算法可以用来求解最小生成树问题，主要包括 Prim 算法和 Kruskal 算法。

##### Prim 算法
Prim 算法从图中的一个顶点开始，逐步将未包含在生成树中的最小权重边添加到生成树中，直到包含所有顶点。其基本步骤如下：
1. 选择任意一个顶点作为起点，将其标记为已访问。
2. 从已访问的顶点集合中选择一条权重最小的边，将该边和另一端的顶点添加到生成树中。
3. 重复步骤2，直到所有顶点都包含在生成树中。

##### Kruskal 算法
Kruskal 算法通过逐步添加边来构建生成树，确保添加的边不会形成环。其基本步骤如下：
1. 将所有边按权重从小到大排序。
2. 依次选择权重最小的边，如果该边连接的两个顶点不在同一个连通分量中，则将该边添加到生成树中。
3. 重复步骤2，直到生成树包含所有顶点。

### Kruskal 算法实现

以下是使用 Kruskal 算法求解最小生成树的 Python 代码示例：

```python
class UnionFind:
    def __init__(self, size):
        self.root = [i for i in range(size)]
        self.rank = [1] * size

    def find(self, x):
        if x != self.root[x]:
            self.root[x] = self.find(self.root[x])
        return self.root[x]

    def union(self, x, y):
        rootX = self.find(x)
        rootY = self.find(y)

        if rootX != rootY:
            if self.rank[rootX] > self.rank[rootY]:
                self.root[rootY] = rootX
            elif self.rank[rootX] < self.rank[rootY]:
                self.root[rootX] = rootY
            else:
                self.root[rootY] = rootX
                self.rank[rootX] += 1

def kruskal(n, edges):
    uf = UnionFind(n)
    mst_cost = 0
    mst_edges = []

    # 按权重排序边
    edges.sort(key=lambda x: x[2])

    for u, v, weight in edges:
        if uf.find(u) != uf.find(v):
            uf.union(u, v)
            mst_cost += weight
            mst_edges.append((u, v, weight))

    return mst_cost, mst_edges

# 测试用例
n = 4
edges = [
    (0, 1, 10),
    (0, 2, 6),
    (0, 3, 5),
    (1, 3, 15),
    (2, 3, 4)
]

mst_cost, mst_edges = kruskal(n, edges)
print(f"Minimum Spanning Tree Cost: {mst_cost}")
print("Edges in MST:")
for u, v, weight in mst_edges:
    print(f"{u} - {v}: {weight}")
```

### 解释
1. **Union-Find 数据结构**：
   - `__init__`: 初始化根节点数组和秩数组。
   - `find`: 通过路径压缩找到节点的根节点。
   - `union`: 通过按秩合并将两个连通分量合并。

2. **Kruskal 算法**：
   - 将所有边按权重排序。
   - 依次选择权重最小的边，如果该边连接的两个顶点不在同一个连通分量中，则将该边添加到生成树中并合并两个连通分量。
   - 重复上述步骤直到生成树包含所有顶点。

### 测试用例
测试用例：
```python
n = 4
edges = [
    (0, 1, 10),
    (0, 2, 6),
    (0, 3, 5),
    (1, 3, 15),
    (2, 3, 4)
]
```
输出：
```
Minimum Spanning Tree Cost: 19
Edges in MST:
2 - 3: 4
0 - 3: 5
0 - 1: 10
```
该输出表示最小生成树的总权重为19，包含的边为 (2, 3), (0, 3), 和 (0, 1)。

### 单源最短路径概述

#### 什么是单源最短路径（Single Source Shortest Path, SSSP）？
单源最短路径问题是图论中的一个经典问题，旨在找到从给定源点到图中其他所有顶点的最短路径。根据图的性质（如是否有负权边、是否有负环等），可以选择不同的算法来解决这个问题。

#### 常见算法
解决单源最短路径问题的主要算法有以下几种：

1. **Dijkstra 算法**
2. **Bellman-Ford 算法**
3. **Floyd-Warshall 算法**（也可用于多源最短路径）
4. **SPFA 算法（Shortest Path Faster Algorithm）**

### Dijkstra 算法
Dijkstra 算法适用于无负权边的加权图。它使用贪心策略，每次选择距离最近的未访问顶点，更新其邻接顶点的最短路径。

#### Dijkstra 算法的步骤：
1. 初始化：将源点的距离设为0，其他所有顶点的距离设为无穷大。
2. 每次从未处理的顶点中选择距离最小的顶点，称为“当前顶点”。
3. 更新当前顶点的邻接顶点的距离，如果通过当前顶点到邻接顶点的路径比已知的最短路径更短，则更新该距离。
4. 重复步骤2和3，直到所有顶点都被处理。

#### Dijkstra 算法的实现
以下是 Dijkstra 算法的 Python 代码示例：

```python
import heapq

def dijkstra(graph, start):
    n = len(graph)
    distances = [float('inf')] * n
    distances[start] = 0
    priority_queue = [(0, start)]  # (distance, node)

    while priority_queue:
        current_distance, current_node = heapq.heappop(priority_queue)

        if current_distance > distances[current_node]:
            continue

        for neighbor, weight in graph[current_node]:
            distance = current_distance + weight

            if distance < distances[neighbor]:
                distances[neighbor] = distance
                heapq.heappush(priority_queue, (distance, neighbor))

    return distances

# 测试用例
graph = [
    [(1, 4), (2, 1)],  # 节点 0 的邻接点和权重
    [(3, 1)],         # 节点 1 的邻接点和权重
    [(1, 2), (3, 5)], # 节点 2 的邻接点和权重
    []                # 节点 3 没有邻接点
]

start_node = 0
print(dijkstra(graph, start_node))  # 输出: [0, 3, 1, 4]
```

### Bellman-Ford 算法
Bellman-Ford 算法适用于含有负权边的图，可以检测负权环。其时间复杂度为 \(O(VE)\)，其中 \(V\) 是顶点数量，\(E\) 是边数量。

#### Bellman-Ford 算法的步骤：
1. 初始化：将源点的距离设为0，其他所有顶点的距离设为无穷大。
2. 反复对每条边进行松弛操作（Relaxation），即对于每条边 \( (u, v, w) \)，如果 \( distances[u] + w < distances[v] \)，则更新 \( distances[v] \)。
3. 重复步骤2，共进行 \( V-1 \) 轮松弛操作。
4. 检查是否存在负权环。如果第 \( V \) 轮仍然可以进行松弛操作，则图中存在负权环。

#### Bellman-Ford 算法的实现
以下是 Bellman-Ford 算法的 Python 代码示例：

```python
def bellman_ford(graph, start):
    n = len(graph)
    distances = [float('inf')] * n
    distances[start] = 0

    for _ in range(n - 1):
        for u in range(n):
            for v, weight in graph[u]:
                if distances[u] + weight < distances[v]:
                    distances[v] = distances[u] + weight

    # 检查负权环
    for u in range(n):
        for v, weight in graph[u]:
            if distances[u] + weight < distances[v]:
                print("Graph contains a negative weight cycle")
                return None

    return distances

# 测试用例
graph = [
    [(1, 4), (2, 1)],  # 节点 0 的邻接点和权重
    [(3, 1)],         # 节点 1 的邻接点和权重
    [(1, 2), (3, 5)], # 节点 2 的邻接点和权重
    []                # 节点 3 没有邻接点
]

start_node = 0
print(bellman_ford(graph, start_node))  # 输出: [0, 3, 1, 4]
```

### 总结
- **Dijkstra 算法**：适用于无负权边的图，时间复杂度为 \(O((V + E) \log V)\)。
- **Bellman-Ford 算法**：适用于含有负权边的图，并能检测负权环，时间复杂度为 \(O(VE)\)。

这两种算法在单源最短路径问题中有广泛应用，根据具体图的性质选择适当的算法可以有效地解决问题。

To solve the problem of determining the order of letters in an alien language given a sorted list of words, we can utilize topological sorting. This problem can be thought of as finding a valid ordering of characters (nodes) given certain precedence constraints (edges).

### Steps to Solve

1. **Build a Graph**: 
   - Use a directed graph where each node represents a character.
   - Add edges between characters based on their order in the words list.

2. **Topological Sort**:
   - Perform a topological sort on the graph to determine the valid order of characters.
   - Use Kahn's algorithm or Depth-First Search (DFS) for topological sorting.
   - If there's a cycle, it means the given order is invalid, and we return an empty string.

### Detailed Steps

1. **Graph Construction**:
   - Compare adjacent words to determine the precedence relationship between characters.
   - For the first differing character between two words, create a directed edge from the character in the first word to the character in the second word.

2. **Topological Sorting**:
   - Track in-degrees of each character (number of incoming edges).
   - Use a queue to perform Kahn's algorithm: start with nodes that have zero in-degree and iteratively remove nodes from the graph, updating in-degrees accordingly.

### Implementation

Here's the Python code implementing the solution:

```python
from collections import defaultdict, deque

def alienOrder(words):
    # Step 1: Create a graph
    graph = defaultdict(set)
    in_degree = {char: 0 for word in words for char in word}

    # Step 2: Build the graph
    for i in range(len(words) - 1):
        first_word = words[i]
        second_word = words[i + 1]
        min_length = min(len(first_word), len(second_word))
        
        # Check that second word isn't a prefix of first word
        if len(first_word) > len(second_word) and first_word[:min_length] == second_word[:min_length]:
            return ""
        
        for j in range(min_length):
            if first_word[j] != second_word[j]:
                if second_word[j] not in graph[first_word[j]]:
                    graph[first_word[j]].add(second_word[j])
                    in_degree[second_word[j]] += 1
                break

    # Step 3: Perform topological sort using Kahn's algorithm
    zero_in_degree_queue = deque([char for char in in_degree if in_degree[char] == 0])
    alien_order = []
    
    while zero_in_degree_queue:
        current_char = zero_in_degree_queue.popleft()
        alien_order.append(current_char)
        
        for neighbor in graph[current_char]:
            in_degree[neighbor] -= 1
            if in_degree[neighbor] == 0:
                zero_in_degree_queue.append(neighbor)
    
    # If not all characters are in alien_order, there was a cycle
    if len(alien_order) != len(in_degree):
        return ""
    
    return "".join(alien_order)

# Test case
words = ["wrt", "wrf", "er", "ett", "rftt"]
print(alienOrder(words))  # Output: "wertf" (or any valid order)
```

### Explanation

1. **Graph Construction**:
   - Initialize a graph and in-degree dictionary.
   - For each pair of adjacent words, determine the first character that differs and add a directed edge from the first character to the second.
   - Update the in-degree of the second character.

2. **Topological Sort**:
   - Initialize a queue with all characters that have zero in-degree.
   - While the queue is not empty, remove a character, append it to the result list, and decrease the in-degree of its neighbors.
   - If a neighbor's in-degree becomes zero, add it to the queue.

3. **Cycle Detection**:
   - If the length of the result list is not equal to the number of unique characters, a cycle exists, and the given order is invalid.

### Conclusion

This approach ensures that we correctly determine the order of characters in the alien language if possible, or return an empty string if the given list of words does not follow a valid order. The solution is efficient, with a time complexity of \(O(C)\), where \(C\) is the total number of characters in all words combined.

