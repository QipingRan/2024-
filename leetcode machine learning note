Â Â Machine Learning Model
Report Issue

The term,Â Machine Learning, often mystifies its nature of computer science, as its name might suggest that the machine is learning as human does, or even better.Â 
Despite the hope that one day we could have machines that think and learn the way that humans do, machine learning nowadays does not go beyond a computerÂ program that performs the predefined procedures. What distinguishes a machine learning algorithm from a non-machine-learning algorithm, such as a program that controls traffic lights, is its ability toÂ adaptÂ its behaviors to new input. And this adaptation, which seems to have no human intervention, occasionally leads to the impression that the machine is actuallyÂ learning. However, underneath the machine learning model, this adaptation of behaviors is as rigid as every bit of machine instructions that are programmed by humans.Â 
So what is a machine learning model ?Â 
A machine learning algorithm is the process that uncovers the underlying relationship within the data.Â 
The outcome of a machine learning algorithm is calledÂ machine learning model, which can be considered as aÂ functionÂ ğ¹F, which outputs certain results, when given the input.
Rather than a predefined and fixed function, a machine learning modelÂ is derivedÂ from historical data. Therefore, when fed with different data, the output of machine learning algorithm changes, i.e. the machine learning model changes.
For example, in the scenario of image recognition, one mightÂ train a machine learning model to recognize the object in the photos. In one case, one might feed thousands of images with and without cats to a machine learning algorithm, in order to obtain a model that is capable to tell whether there is a cat in a photo. As a result, the input of the generated model would be a digital photo, and the output is a boolean value indicating the existence of a cat on the photo.

The machine learning model in the above case is a function that maps multiple dimensional pixel values to a binary value. Assume that we have a photo of 3 pixels, and the value of each pixel range from 0 to 255. Then the mapping space between the input and the output would beÂ (256Ã—256Ã—256)Ã—2(256Ã—256Ã—256)Ã—2, which is around 33 million. We can convince ourselves that it must be a daunting task to learn this mapping (machine learning model) in a real-world case where a normal photo accounts for millions of pixels and each pixel is composed of three colors (RGB) instead of a single grey color.
The task of machine learning, is toÂ learnÂ the function, from the vast mapping space.
The process of discovering the latent mapping relationship between millions of pixels and a Yes/No answer, is what we callÂ machine learning, in this case. Most of the time, what we learnÂ at the end, is anÂ approximationÂ to this underlying relationship. Due to its nature of approximation, one should not be disappointed to find that the results of a machine learning model is often notÂ 100%100%Â accurate. Before the wide application of deep learning in 2012, the best machine learning model can only achieve aroundÂ 75%75%Â accuracy in theÂ ImageNet visual recognition challenge. Till nowadays, still, no machine learning model can claimÂ 100%100%Â accuracy, although there are models that make fewer errors (<5%<5%)Â than humans in this task.Â 

Given a machine learning problem, first of all, one can determine whether it is aÂ supervisedÂ orÂ unsupervisedÂ problem.
For any machine learning problem, we start from a data set, which consists of a group ofÂ samples. Each sample can be represented as a tuple ofÂ attributes.Â 
For example, there is a famous classic data set calledÂ Iris, which is first published in the paper ofÂ "The use of multiple measurements in taxonomic problems" - Ronald. A. Fisher (1936)Â [1].Â The Iris data set consists of measurement for 150 samples of iris flower. Each sample contains the measurementÂ for the length and the width of its petal and sepal, and a class attribute that indicates the category of iris flower, namelyÂ setosa,Â versicolorÂ andÂ virginica. Here are a few samples of the Iris data set.

Â 
Supervised Learning

In aÂ supervisedÂ learning task, the data sample would containÂ a target attributeÂ ğ‘¦y, also known asÂ ground truth. And the task is to learn a function F, that takes the non-target attributes X and output a value that approximates the target attribute,Â i.e.Â ğ¹(ğ‘‹)â‰ˆğ‘¦F(X)â‰ˆy.Â The target attributeÂ ğ‘¦yÂ serves as a teacher to guide the learning task, since it provides a benchmark on the results of learning. Hence, the task is called supervised learning.Â 
In the Iris data set, theÂ classÂ attribute (category of iris flower) can serve as a target attribute. The data with a target attribute is often called "labeled" data. Based on the above definition, for the task of predicting the category of iris flower with the labeled data, one can tell thatÂ it is a supervised learning task.Â 
Â 
Unsupervised Learning

In contrary to the supervised learning task, we do not have the ground truth in anÂ unsupervisedÂ learning task. One is expected to learn the underlying patterns or rules from the data, without having the predefined ground truth as the benchmark.
One might wonder, without theÂ supervisionÂ of the ground truth, can we still learn anything? The answer is yes. Here are a few examples of the unsupervised learning tasks:
ï‚·Clustering: given a data set, one can cluster the samples into groups, based on the similarities among the samples within the data set. For instance, a sample could be a customer profile, with attributes such as the number of items that the customer bought, the time that the customer spent on the shopping siteÂ etc. One can cluster the customer profiles into groups, based on the similarities of the attributes. With the clustered groups, one could devise specific commercial campaigns targeting each group, which might helpÂ attract and retain customers.Â 
ï‚·Association:Â  given a data set, the association task is to uncover the hidden association patterns among the attributes of a sample. For instance,Â  a sample could be a shopping cart of a customer, where each attribute of the sample is a merchandise. By looking into the shopping carts, one might discover that customers who bought beersÂ oftenÂ bought diapers as well,Â i.e.Â there is a strong association between the beer and the diaper in the shopping cart. With this learned insight, the supermarket could rearrange those strongly associated merchandise into the nearby corners, in order to promote the sales of one or another.
Â 
Semi-supervised Learning

In a scenario where the data set is massive but the labeled sample are few,Â one mightÂ find the application of both supervised and unsupervised learning. We can call this task asÂ semi-supervised learning.
In many scenarios, it is prohibitively time-consuming and expensive to collect a large amount of labeled data, which often involves manual efforts. It takes two and a half years for a research team from Stanford to curate the famousÂ ImageNetÂ which contains millions of images with thousands of manually labeled categories. As a result, it is often the case that one has a large amount of data, yet few of them are accurately "labeled", e.g. videos without categoryÂ or even a title.
By combining both the supervised and unsupervised learning in a data set with few labels, one could exploit the data set to a better extent and obtain a better result than just applying each of them individually.Â 
For example, one would like to predict the label of images, but onlyÂ 10%10%Â of the images are labeled. By applying supervised learning,Â we train a model with the labeled data, then we apply the model to predict the unlabeled data.Â It would be hard to convince ourselves that the model would be general enough, after all we learned from only the minority of data set. A better strategy could be to first cluster the images into groups (unsupervised learning), and then apply the supervised learning algorithm on each of the groups individually. The unsupervised learning in the first stage could help us to narrow down the scope of learning so that the supervised learning in the second stage could obtain better accuracy.
Â Â Classification VS. Regression
Report Issue

In the previous section, we define a machine learning model as a functionÂ ğ¹F, that takes certain input and generates an output.Â Often weÂ further distinguishÂ the machine learning models asÂ classificationÂ andÂ regression, based on the type of output values.
If the output of a machine learning model isÂ discreteÂ values,Â e.g.Â a boolean value, we then call itÂ a classification model. While we call the model that outputsÂ continuousÂ valuesÂ as regression model.
Â 
Classification Model

For example, the model that tells whether a photo contains a cat or not can be considered asÂ a classification model, since we can represent the output with a boolean value.

To be more specific, the input can be represented as a matrixÂ ğ‘€MÂ with dimensions ofÂ ğ»Ã—ğ‘ŠHÃ—WÂ whereÂ ğ»HÂ is the height of the photo in pixels andÂ ğ‘ŠWÂ is the width of the photo. Each element within the matrix is the grayscale value of each pixel in the photo,Â i.e.Â an integer valueÂ betweenÂ [0,255][0,255]Â that indicates the intensity of color. The expected output of the modelÂ would be a binary valueÂ [1âˆ£0][1âˆ£0], indicating whether the photo shows a cat or not. To summarize, our cat-photo-recognition modelÂ ğ¹FÂ can be formulated as follows:
ğ¹(ğ‘€[ğ»][ğ‘Š])=1âˆ£0,whereÂ ğ‘€[ğ‘–][ğ‘—]âˆˆ[0,255],0<ğ‘–<ğ»,0<ğ‘—<ğ‘ŠF(M[H][W])=1âˆ£0,whereÂ M[i][j]âˆˆ[0,255],0<i<H,0<j<W
And theÂ goal of machine learning is to discover aÂ function that is as general as possible, which has a high probability to give the right answer for unseen data.
Â 
Regression Model

As for the examples of regression model, one can consider a model that estimatesÂ the price of a real estate, given the characteristics such as the surface, the type of real estate (e.g.Â house, apartment), and of course the location. In this case, we can consider the expected output as a real valueÂ ğ‘âˆˆğ‘…pâˆˆR, therefore it is a regression model. Note, in this example, the raw data that we have is not all numeric, but certain of them areÂ categorical, such as the type of real estate. This is often the case in real-world problems.Â 
For each real estate that is under consideration, we can represent its characteristics as a tupleÂ ğ‘‡T, where each element within the tuple is either a numeric value, or a categorical value that represents one of its attributes. The elements are also calledÂ featuresÂ in many cases. To summarize, we can formulate our real-estate-price-estimation model as follows:
ğ¹(ğ‘‡)=ğ‘,whereÂ ğ‘âˆˆğ‘…F(T)=p,whereÂ pâˆˆR
To be more specific, let's consider a real estate with the following features:
surface =Â 120Â ğ‘š2120Â m2,Â  type = ' apartment', location = ' NY downtown', year_of_construction = 2000
Now given the above features, if ourÂ modelÂ ğ¹FÂ gives a value likeÂ 10,000$10,000$, then most likely that our model is not a good fit for the problem.Â 
As an example, in the following graph, we show a regression model with the surface of the estateÂ as the only variable, and the price of the estate as the output. Â Â 

Speaking of features, we would also like to mention that some of the machine learning models (e.g.Â decision tree)Â can handle directly the non-numeric feature as it is, while more often one has toÂ transformÂ those non-numeric features into numeric one way or another.
Â 
Problem Conversion

Given a real-world problem, sometimes one can easily formulate it and quickly attribute it to either a classification or regression problem. However, sometimesÂ the boundary between these two models is not clear, and one can transform a classification problem into a regression problem, and vice versa.Â 
In the above example of real estate price estimation, it seems difficult to predict the exact price of a real estate. However, if we reformulate the problem as predicting the price range of real estateÂ instead of a single price tag, then we could expect to obtain a more robust model. As a result, we transform the problem into a classification problem, instead of regression.
As to our cat-photo-recognition model, we can also transform it from classification to regression. Instead of giving a binary value as the output, we could define a model to give a probability valueÂ [0,100%][0,100%]Â on whether the photo shows a cat. In this way, one can compare the nuance between models and further tune the models. For instance, for a photo with a cat, a model A gives the probabilityÂ 1%1%, whileÂ model B gives the probabilityÂ 49%49%Â for the same photo. Although both models fail to give the right answer, one can tell that model B is closer to the truth. In this scenario, one often applies one of the machine learningÂ models calledÂ Logistic Regression, which gives continuous probability values as output, but it is served to solve the classification problem.
Â Â Data, Data, Data !
Report Issue

The ultimate goal of the machine learning workflow is to build a machine learning model. We obtain the model from the data. As a result, it is the data that determines theÂ upper boundÂ of performance thatÂ the model can achieve. There are numerous models that can fit a specific data. The best that we can do, is to find a model that can approach the most to the upper bound set by the data. We cannot really expect that a model can learn something else out of the scope of data.
Rule of thumb:Â garbage in, garbage out.
It might be appropriateÂ to illustrate the above pointÂ with the parable of the blind men and an elephant. The story goes like this, a group of blind men, who have never come across an elephant before, would like to learn and conceptualize what an elephant is like by touching it. Each man touches a part of the body, such as leg, tusk or tailÂ etc. While each of them got a part of the reality, none of them has the whole picture of an elephant. Therefore, none of them actually learned the trueÂ image of an elephant.

Now, back to our machine learning task, the training data we got could be those images of legs or tusks from an elephant, while during the test processing, the testing data we got are the full portraitsÂ of elephants. It would not be surprising to find out that our trained model does not perform well in this case, since we do not have theÂ high-qualityÂ training data that is closerÂ to the realityÂ in the first place.Â 
One might wonder that if the data is really important, then why not feeding the "high-quality" data such as full portraits of elephantsÂ intoÂ the algorithm, instead of snapshots on parts of the elephant body. Because, facing a problem, we or the machine, like the "blind-men", often struggle to gather the data that captures the essential characteristics of the problem, either due to the technical issues (e.g.Â data privacy)Â or simply because we do not perceive the problem in the right way.Â 
In the real world, the data we got reflectsÂ a part ofÂ reality in a favorableÂ case, or it could be some noise in a less favorable case, or in the worst case,Â even a contradiction to the reality. Regardless of the machine learning algorithms, one would not be able to learn anything from data that contains too much noise or is too inconsistent with the reality.
Â Â Data, Data, Data !
Report Issue

The ultimate goal of the machine learning workflow is to build a machine learning model. We obtain the model from the data. As a result, it is the data that determines theÂ upper boundÂ of performance thatÂ the model can achieve. There are numerous models that can fit a specific data. The best that we can do, is to find a model that can approach the most to the upper bound set by the data. We cannot really expect that a model can learn something else out of the scope of data.
Rule of thumb:Â garbage in, garbage out.
It might be appropriateÂ to illustrate the above pointÂ with the parable of the blind men and an elephant. The story goes like this, a group of blind men, who have never come across an elephant before, would like to learn and conceptualize what an elephant is like by touching it. Each man touches a part of the body, such as leg, tusk or tailÂ etc. While each of them got a part of the reality, none of them has the whole picture of an elephant. Therefore, none of them actually learned the trueÂ image of an elephant.

Now, back to our machine learning task, the training data we got could be those images of legs or tusks from an elephant, while during the test processing, the testing data we got are the full portraitsÂ of elephants. It would not be surprising to find out that our trained model does not perform well in this case, since we do not have theÂ high-qualityÂ training data that is closerÂ to the realityÂ in the first place.Â 
One might wonder that if the data is really important, then why not feeding the "high-quality" data such as full portraits of elephantsÂ intoÂ the algorithm, instead of snapshots on parts of the elephant body. Because, facing a problem, we or the machine, like the "blind-men", often struggle to gather the data that captures the essential characteristics of the problem, either due to the technical issues (e.g.Â data privacy)Â or simply because we do not perceive the problem in the right way.Â 
In the real world, the data we got reflectsÂ a part ofÂ reality in a favorableÂ case, or it could be some noise in a less favorable case, or in the worst case,Â even a contradiction to the reality. Regardless of the machine learning algorithms, one would not be able to learn anything from data that contains too much noise or is too inconsistent with the reality.
Â Machine Learning Workflow
Report Issue

In the previous section, we clarify the notion of machine learning model.Â In this section, we discuss a typicalÂ workflowÂ to construct a machine learning model.
First of all, one cannot talk about machine learning, without mentioning about theÂ data. The relationship between the data and the machine learning model, is as critical as the fuel to the engine of rocket.Â 
Â 
Data-Centric Workflow

The workflow to build a machine learning model is centralized around the data.
It is not exaggerating to say that the data dictates how the machine learning model is built. In the following graph, we illustrate a typical workflow involved in a project of machine learning.
Â 

Starting from the data, we first determine which type of machine learning problems we would like to solve,Â i.e.Â supervisedÂ vs.Â unsupervised. We sayÂ that theÂ data isÂ labeled, if one of the attributes in the data is the desired one,Â i.e.Â the target attribute. For instance, in the task of telling whether there is a cat on a photo, the target attribute of the dataÂ could be a boolean value [Yes|No]. If this target attribute exists, then we say the data is labeled, and it is a supervised learning problem.Â 
For the supervised machine learning algorithms, we further determine the type ofÂ the generated model:Â classificationÂ orÂ regression, based on the expected output of the model,Â i.e.Â discrete value for classification model and continuous value for the regression model.
OnceÂ we determine on the type of modelÂ that we would like to build out of the data, we then go ahead to perform theÂ feature engineering, which is a group of activities that transform the data into the desired format. Here are a few examples:
ï‚·For almost all cases, weÂ splitÂ the data into two groups: training and testing. The training dataset is used during the process to train a model, while the testing dataset is then used to test or validate whether the model we build is generic enough that can be applied to theÂ unseen data.Â 
ï‚·The raw dataset is oftenÂ incompleteÂ with missing values. Therefore, one might need to fill those missing values with various strategies such as filling with the average value.Â 
ï‚·The dataset often contains categorical attributes, such as country, genderÂ etc.Â AndÂ it is often the case that oneÂ needs toÂ encodeÂ those categorical string valuesÂ into numerical one, due to the constraintsÂ of algorithm. For example,Â the Linear Regression algorithm can only deal with vectors of real values as input.Â 
The process of feature engineering isÂ notÂ aÂ one-offÂ step. Often one needs to repeatedly come back to the feature engineering later in the workflow.
Once the data is ready, we then select one of the machine learning algorithms, and start to feed the algorithmÂ with the preparedÂ trainingÂ data. This is what we call theÂ training process.
Once we obtain our model at the end of the training process, we then test the model with the reservedÂ testing data. This is what we call theÂ testing process.Â 
It is rarely the case that we are happy with our first trained model. One would then go back to the training process and tune some parameters that are exposed by the model that we selected. This is what we called theÂ hyper-parameter tuning. The reason that itÂ is highlighted as 'hyper' is because the parameters that weÂ tuneÂ are the outermostÂ interface that we interact with the model, which would eventually have impacts on the underlyingÂ parameters of the model. For example, for the decision tree model, one of its hyper-parameters would be the maximum height of the tree. Once set manually before the training, it would limit the number of branches and leaves that a decision tree can grow at the end, which are the underlying parameters that a decision tree model consists of.Â 
As one can see, the steps involved in the machine learning workflowÂ form aÂ cycleÂ with a focus on the data.Â 
Underfitting VS. Overfitting
Report Issue

For supervised learning algorithms,Â e.g.Â classification and regression, there are two common cases where the generated model does not fit well the data:Â underfittingÂ andÂ overfitting.Â 
An important measurement for supervised learning algorithms, is theÂ generalization, which measures how well that a model derived from the training data can predict the desired attribute of the unseen data. When we say a model is underfitting or overfitting, it implies that the model does not generalized well to the unseen data.Â 
A model that fits well with the training data does not necessarily imply that it would generalize well to the unseen data. BecauseÂ 1). the training data are just samples we collect from the real world, which represents only a proportion of reality. It could be the case that the training data is simply not representative, thus even the model fits perfectly the training data, it would not fit well with the unseen data.Â 2). the data that we collect contains noises and errors inevitably. The model that fits perfectly with the data, would also captureÂ the undesired noises and errors by mistake, which would eventually lead to bias and errors in the prediction for the unseen data.
Before we dive down into the definition of underfitting and overfitting, here we show some examples of what underfitting and overfitting models look like, in the task of classification.

Â 
Underfitting

An underfitting model is the one that does not fit wellÂ with the training data,Â i.e.Â significantly deviatedÂ from the ground truth.Â 
One of the causes of underfitting could be that the model is over-simplified for the data, therefore it is not capable to capture the hidden relationship within the data. As one can see from the above graph No.Â (1), in order to separate the samples,Â i.e.Â classification, a simple linear model (a line) is not capable to clearly draw the boundary amongÂ the samples of different categories, which results in significant misclassification.
As a countermeasure to avoid the above cause of underfitting, one can choose an alternative algorithm that is capable to generate a more complex model from the training data set.
Â 
Overfitting

An overfitting model is the one that fits well with the training data,Â i.e.Â little or no error, however it does not generalized well to the unseen data.
Contrary to the case of underfitting, an over-complicated model that is able to fit every bit of the data, would fall into the traps of noises and errors. As one can see from the above graph No.Â (3), the model managed to have less misclassification in the training data, yet it is more likely that it would stumble on the unseen data.
Similarly with the underfitting case, to avoid the overfitting, one can try out another algorithm that could generate a simpler model from the training data set. Or more often, one staysÂ with the original algorithm that generated the overfitting model, but adds aÂ regularizationÂ term to the algorithm,Â i.e.Â penalizing the model that is over-complicated so that the algorithm is steered to generate a less complicated model while fitting the data.
Underfitting å’Œ Overfitting æ˜¯æœºå™¨å­¦ä¹ ä¸­ä¸¤ä¸ªå¸¸è§çš„é—®é¢˜ï¼Œå®ƒä»¬åˆ†åˆ«æè¿°äº†æ¨¡å‹å¯¹æ•°æ®çš„é€‚åº”ç¨‹åº¦ï¼š

### Underfittingï¼ˆæ¬ æ‹Ÿåˆï¼‰

**å®šä¹‰ï¼š** æ¨¡å‹æ— æ³•æ•æ‰è®­ç»ƒæ•°æ®ä¸­çš„åŸºæœ¬æ¨¡å¼å’Œç‰¹å¾ï¼Œè¡¨ç°ä¸ºæ¨¡å‹å¯¹æ•°æ®çš„æ‹Ÿåˆç¨‹åº¦ä¸è¶³ã€‚

**åŸå› ï¼š**
- æ¨¡å‹è¿‡äºç®€å•ï¼Œä¸èƒ½è¡¨ç¤ºæ•°æ®çš„å¤æ‚æ€§ã€‚
- ç‰¹å¾é€‰æ‹©ä¸è¶³ï¼Œé‡è¦çš„ä¿¡æ¯è¢«é—æ¼ã€‚
- è®­ç»ƒæ—¶é—´å¤ªçŸ­ï¼Œæ²¡æœ‰å……åˆ†å­¦ä¹ æ•°æ®ã€‚

**è¡¨ç°ï¼š**
- åœ¨è®­ç»ƒé›†å’ŒéªŒè¯é›†ä¸Šçš„è¡¨ç°éƒ½å¾ˆå·®ã€‚
- é«˜è®­ç»ƒè¯¯å·®å’Œé«˜éªŒè¯è¯¯å·®ã€‚

**è§£å†³æ–¹æ³•ï¼š**
- å¢åŠ æ¨¡å‹å¤æ‚åº¦ï¼Œä¾‹å¦‚ä½¿ç”¨æ›´å¤æ‚çš„æ¨¡å‹æˆ–å¢åŠ æ¨¡å‹å‚æ•°ã€‚
- æ·»åŠ æ›´å¤šçš„ç‰¹å¾æˆ–ä½¿ç”¨æ›´å¥½çš„ç‰¹å¾å·¥ç¨‹æ–¹æ³•ã€‚
- å¢åŠ è®­ç»ƒæ—¶é—´ï¼Œç¡®ä¿æ¨¡å‹å……åˆ†å­¦ä¹ æ•°æ®ã€‚

### Overfittingï¼ˆè¿‡æ‹Ÿåˆï¼‰

**å®šä¹‰ï¼š** æ¨¡å‹è¿‡äºå¤æ‚ï¼Œä»¥è‡³äºèƒ½å¤Ÿè®°ä½è®­ç»ƒæ•°æ®ä¸­çš„å™ªå£°å’Œå¼‚å¸¸ï¼Œä»è€Œåœ¨è®­ç»ƒæ•°æ®ä¸Šè¡¨ç°å¾ˆå¥½ï¼Œä½†åœ¨æ–°æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›å¾ˆå·®ã€‚

**åŸå› ï¼š**
- æ¨¡å‹è¿‡äºå¤æ‚ï¼ŒåŒ…å«å¤ªå¤šå‚æ•°ã€‚
- è®­ç»ƒæ—¶é—´è¿‡é•¿ï¼Œæ¨¡å‹è®°ä½äº†è®­ç»ƒæ•°æ®çš„å™ªå£°ã€‚
- ç‰¹å¾é€‰æ‹©è¿‡å¤šï¼ŒåŒ…å«äº†ä¸å¿…è¦çš„ä¿¡æ¯ã€‚

**è¡¨ç°ï¼š**
- åœ¨è®­ç»ƒé›†ä¸Šçš„è¡¨ç°å¾ˆå¥½ï¼Œä½†åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°å¾ˆå·®ã€‚
- ä½è®­ç»ƒè¯¯å·®å’Œé«˜éªŒè¯è¯¯å·®ã€‚

**è§£å†³æ–¹æ³•ï¼š**
- ç®€åŒ–æ¨¡å‹ï¼Œå‡å°‘æ¨¡å‹å‚æ•°æˆ–ä½¿ç”¨æ›´ç®€å•çš„æ¨¡å‹ã€‚
- ä½¿ç”¨æ­£åˆ™åŒ–æ–¹æ³•ï¼ˆå¦‚L1, L2æ­£åˆ™åŒ–ï¼‰æ¥é™åˆ¶æ¨¡å‹å¤æ‚åº¦ã€‚
- ä½¿ç”¨äº¤å‰éªŒè¯æ¥ç¡®ä¿æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
- å¢åŠ è®­ç»ƒæ•°æ®é‡ï¼Œä½¿æ¨¡å‹æ›´èƒ½ä»£è¡¨æ•°æ®çš„çœŸå®åˆ†å¸ƒã€‚

### è§†è§‰åŒ–ç†è§£

**æ¬ æ‹Ÿåˆï¼š**
![Underfitting](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Overfitting_svg.svg/800px-Overfitting_svg.svg.png)

**è¿‡æ‹Ÿåˆï¼š**
![Overfitting](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Overfitting_svg.svg/800px-Overfitting_svg.svg.png)

åœ¨è¿™ä¸¤å¼ å›¾ä¸­ï¼Œå·¦è¾¹è¡¨ç¤ºæ¬ æ‹Ÿåˆçš„æƒ…å†µï¼Œæ¨¡å‹ï¼ˆç»¿çº¿ï¼‰æ²¡æœ‰å¾ˆå¥½åœ°æ‹Ÿåˆæ•°æ®ç‚¹ï¼ˆçº¢ç‚¹ï¼‰ã€‚å³è¾¹è¡¨ç¤ºè¿‡æ‹Ÿåˆçš„æƒ…å†µï¼Œæ¨¡å‹ï¼ˆç»¿çº¿ï¼‰è¿‡äºå¤æ‚ï¼Œç”šè‡³æ•æ‰åˆ°äº†æ•°æ®ä¸­çš„å™ªå£°ã€‚

ç†è§£å’Œè§£å†³æ¬ æ‹Ÿåˆä¸è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œæ˜¯æå‡æœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½çš„å…³é”®ã€‚
Â Â Bias VS. Variance
Report Issue

In this article, we will talk about the notions ofÂ biasÂ andÂ variance, which provides another perspective to look at the phenomenon ofÂ underfittingÂ andÂ overfittingÂ that we discussed before.
Before we start, we would like to put a statement below. It probably does not ring a bell for you at the moment, but hopefully you would getÂ the answer yourself once you go through the article.
Bias is a learnerâ€™s tendency to consistently learn the same wrong thing. Variance is the tendency to learn random things unrelated to the real signalÂ [1].Â 
In order to define bias and variance, we need to first define the notion ofÂ main predictionÂ [2]. For those of you who are already familiar with the concepts of model and loss function, you can skip the part of definitions, and jump directly to the section of Main Prediction. For the sake of completeness, we first give the definitions of basic conceptsÂ before diving into the main subject of this article.
Â 
Definitions

Given a training setÂ ğ‘ ={(ğ‘¥1âƒ—,ğ‘¡1),....(ğ‘¥ğ‘›âƒ—,ğ‘¡ğ‘›)}s={(x1â€‹â€‹,t1â€‹),....(xnâ€‹â€‹,tnâ€‹)}, a learner (a machine learning algorithm) produces a modelÂ ğ¹F. Given a test exampleÂ ğ‘¥ğ‘˜âƒ—xkâ€‹â€‹, this model produces aÂ predictionÂ ğ‘¦ğ‘˜=ğ¹(ğ‘¥ğ‘˜âƒ—)ykâ€‹=F(xkâ€‹â€‹). Each sample in the training set consists of two elements,Â ğ‘¥ğ‘–âƒ—xiâ€‹â€‹Â is a vector of attributes associated with the sample, andÂ ğ‘¡ğ‘–tiâ€‹Â is the target attributeÂ to predict for the sample.
For example, a train sample might look like:Â ğ‘¥ğ‘–âƒ—xiâ€‹â€‹= (type='appartment', location='LA', surface='120m2'),Â ğ‘¡ğ‘–tiâ€‹Â = (price='420,000$'). The task of a learner is then to predict the price of an estate given its properties.
Given an training sampleÂ (ğ‘¥ğ‘–âƒ—,ğ‘¡ğ‘–)(xiâ€‹â€‹,tiâ€‹), the learner produces a prediction asÂ ğ¹(ğ‘¥ğ‘–âƒ—)F(xiâ€‹â€‹), we then define theÂ loss functionÂ ğ¿(ğ¹(ğ‘¥ğ‘–âƒ—),ğ‘¡ğ‘–)L(F(xiâ€‹â€‹),tiâ€‹)Â as the cost that is incurred by the difference between the predictionÂ ğ¹(ğ‘¥ğ‘–âƒ—)F(xiâ€‹â€‹)Â and the true valueÂ ğ‘¡ğ‘–tiâ€‹Â associated with the sample. The larger the difference, the biggerÂ the loss.Â If the target attributeÂ ğ‘¡ğ‘–tiâ€‹Â is of numerical value, a common loss function would be aÂ square error,Â i.e.Â ğ¿(ğ¹(ğ‘¥ğ‘–âƒ—),ğ‘¡ğ‘–)=(ğ¹(ğ‘¥ğ‘–âƒ—)âˆ’ğ‘¡ğ‘–)2L(F(xiâ€‹â€‹),tiâ€‹)=(F(xiâ€‹â€‹)âˆ’tiâ€‹)2. Following the above example, if a modelÂ ğ¹FÂ produces the price of the above exampleÂ ğ‘¥ğ‘–âƒ—xiâ€‹â€‹Â as '410,000$', then the result of the loss function would beÂ (420,000âˆ’410,000)2=108(420,000âˆ’410,000)2=108.Â 
Â 
Main Prediction

GivenÂ a loss functionÂ ğ¿LÂ and sets of training setÂ ğ‘†={ğ‘ 1,ğ‘ 2...ğ‘ ğ‘›}S={s1â€‹,s2â€‹...snâ€‹}, the main prediction for a learnerÂ is defined asÂ ğ‘¦ğ‘š=ğ‘ğ‘Ÿğ‘”ğ‘šğ‘–ğ‘›ğ‘¦â€²ğ¸ğ‘†(ğ¿(ğ‘¦,ğ‘¦â€²))ymâ€‹=argminyâ€²â€‹ESâ€‹(L(y,yâ€²)).
For each training setÂ ğ‘ ğ‘–siâ€‹, we train a modelÂ ğ¹ğ‘–Fiâ€‹Â with a given learner. For a given training sample, we then produce a set of predictionsÂ ğ‘Œ={ğ‘¦1,ğ‘¦2...ğ‘¦ğ‘›}Y={y1â€‹,y2â€‹...ynâ€‹}Â withÂ ğ‘¦ğ‘–yiâ€‹Â corresponding to the result produced by the modelÂ ğ¹ğ‘–Fiâ€‹.Â TheÂ main predictionÂ ğ‘¦ğ‘šymâ€‹Â is the predictionÂ ğ‘¦â€²yâ€²Â whose average loss with regardsÂ to all the predictions inÂ ğ‘ŒYÂ is minimum (i.e., it is the prediction that â€œdiffers leastâ€ from all the predictions inÂ ğ‘ŒYÂ according toÂ ğ¿L).Â [2]
In a particular case, when the loss function is square error,Â i.e.Â ğ¿(ğ‘¦,ğ‘¦â€²)=(ğ‘¦âˆ’ğ‘¦â€²)2L(y,yâ€²)=(yâˆ’yâ€²)2, the main prediction with regards to the entire training setsÂ ğ‘†S, is thenÂ the mean of the predictions,Â i.e.Â ğ‘¦ğ‘š=ğ¸ğ‘†(ğ‘Œ)=1ğ‘›âˆ‘ğ‘–=1ğ‘›ğ‘¦ğ‘–ymâ€‹=ESâ€‹(Y)=n1â€‹âˆ‘i=1nâ€‹yiâ€‹. One can refer to the paperÂ [2]Â in the referencesÂ for the deduction process.
We can interpret the main prediction as the expect answer for a given training sample,Â from a given learner (a machine learning algorithm).
To better understand the concept of the main prediction, let's imagineÂ that a learner is playing aÂ dart-throwing game,Â i.e.Â a learner is a player.Â Each time a player throws a dart, it involves two corresponding activities:Â 1). the player poses and aims,Â i.e.Â the learner trains a model from a given training dataset.Â 2).Â the player throws the dart,Â i.e.Â we say that the model trained by the learnerÂ produces a prediction. Intuitively, the bullseye is the target of the prediction. The closer a dart to the bullseyes, the better the player (learner) is.
Then each time before the player throws a dart, we can ask ourselves a question:Â how manyÂ points that the player would score. And this is where the concept of the main prediction comes into the picture. As it turns out that the best guess that one can bet on is the main prediction of this learner (player), which couldÂ be approximated by the average score that the player has achieved during all past games. For example, we can bet that a dart out ofÂ the hand ofÂ a good player would not stray too far awayÂ from the bullseye.
Intuitively, we can considerÂ the main prediction as the generalÂ tendencyÂ (performance) of a learner,Â i.e.Â expected points that a player can score in a game.Â 
With the notionÂ of the main prediction, we now can define the notions of bias and variance.Â 
Â 
Bias

The bias of a learner (algorithm) on the exampleÂ (ğ‘¥ğ‘–âƒ—,ğ‘¡ğ‘–)(xiâ€‹â€‹,tiâ€‹)Â is defined asÂ ğµ(ğ‘¥ğ‘–âƒ—)=ğ¿(ğ‘¦ğ‘š,ğ‘¡ğ‘–)B(xiâ€‹â€‹)=L(ymâ€‹,tiâ€‹), whereÂ ğ‘¦ğ‘šymâ€‹Â is the main prediction,Â ğ‘¡ğ‘–tiâ€‹Â is the target value, andÂ ğ¿LÂ is the loss function.
In a word, the bias of a learner, with regards to an example, is the loss incurred by the difference between the main prediction (the general tendency) and the actual value of the target attribute (target value).
The closer the main prediction to the target value, the less the loss. The more likely a learner producesÂ a model that gives the right prediction, the less bias the learnerÂ has.
According to the definition, the main prediction of a learnerÂ is the mean prediction of all models that are produced by the learner from various training sets.Â Therefore, given a learner, with infiniteÂ training sets, one can assume that the main prediction would converge to a constant value that is linked with the nature of the learner. When the bias of a learnerÂ is zero, we can say thatÂ the learner can produce a number of models whose mean prediction is theÂ desired target valueÂ [2].Â 
If a learner has a relatively high bias and the learner does indeed learn something from the data, then we can say that the model resulted from the learner has a high tendency to produce an erroneous prediction.
Â 
Variance

The variance of a learner (algorithm) on the exampleÂ (ğ‘¥ğ‘–âƒ—,ğ‘¡ğ‘–)(xiâ€‹â€‹,tiâ€‹)Â is defined asÂ ğ‘‰(ğ‘¥ğ‘–âƒ—)=ğ¸ğ‘†(ğ¿(ğ‘¦ğ‘š,ğ‘¦))V(xiâ€‹â€‹)=ESâ€‹(L(ymâ€‹,y)), whereÂ ğ‘¦ğ‘šymâ€‹Â is the main prediction,Â ğ‘¦yÂ is a prediction produced from a model that is trained on a training setÂ ğ‘ âˆˆğ‘†sâˆˆS,Â ğ¿LÂ is the loss function, andÂ ğ¸ğ‘†ESâ€‹Â is the average function over the list of loss values.Â 
In a word,Â ğ‘‰(ğ‘¥ğ‘–âƒ—)V(xiâ€‹â€‹)Â measures the loss incurred by its fluctuation around the main prediction in response to different training sets.
The more stable the performance of a learner, the less its variance. In the game of dart, a learner withÂ high varianceÂ corresponds toÂ a lousy player whoÂ rarely lands the dart in the same place. On the other hand, a learner with low variance could correspond toÂ a decent player who rarely misses the bullseye.
The variance is independent of the true value of the predicted variable, and is zero for a learner that always makes the same prediction regardless of the training setÂ [2].
If a learner has high variance, then we would know that the learner is highly sensitive to the training data set,Â i.e.Â a minor noise in the training data could lead to an ill-formed model that produces wrong predictions.Â 
Â 
Bias-Variance Coordinate

The bias and variance can serve as metrics to evaluate the performance of a learner.
Below we draw a plot with two dimensions: the X dimension indicates the variance of a learner, and the Y dimension indicates the bias of a learner. Following the dart game example that we discussed in previous sections, the learner assumes the role of a dart player. Each dot on the board corresponds to a prediction made by the learner. The closer is the dot to the bullseye, the closer is the prediction to the target value. We then can classify the learners into four different types as follows:

- (1). AnÂ ideal learnerÂ would situate at the low-left part of the plot, where we find the low bias as well as low variance. This is the decent dart player that rarely misses the bullseye. A good playerÂ never makes mistakes,Â i.e.Â a good learner always makes good predictions.Â 
- (2). Now, moving to the right-hand side of the ideal learner, we have aÂ fair learnerÂ who manages to score some points (i.e.Â low bias), yet the darts are all over the places (i.e.Â high variance). The learners that are situated in this area are usually complex algorithms that could manageÂ to train some decent models sometimes, but in general, the performance of the model is not too promising. The case where we do not obtain a good model, is also calledÂ overfitting,Â i.e.Â the model pays too much attention to the irrelevant noise.
- (3). We then move to the up-right part of the plot, here we find theÂ terrible learner, who has both high bias and high variance. The terrible learner is not able to extract information from the data and basically learns nothing. The prediction that learner produces is not relevant (high bias), and what's even worse, the learner is not consistent with its strategy but making a random guess (high variance).Â 
- (4). Right next to the terribleÂ learner, we find theÂ naive learner, who has high bias yet low variance. The naive learner often adopts some straightforward strategies, which could explainÂ why it produces stable outputs (low variance). But the strategy is too simple to capture the essential information from the data, which results in producing aÂ underfittedÂ model.
Â 
Bias-Variance TradeoffÂ 

Bias is reduced and variance is increased in relation to the complexity of the models produced by a learner.
The correlation between the model complexity and bias-variance can be described inÂ the following graph:

One can draw a few information from the above graph:
ï‚·When the model becomes more complex, it could potentially fit better the training data set, as a result, the bias is reduced.
ï‚·Meanwhile, when the model becomes more complex, the variance increases,Â since the model becomes more sensitive to the noise in the data.
ï‚·As one can see, the total error of a model is correlated to the components ofÂ Bias2Bias2Â andÂ VarianceVariance.Â 
Indeed, when the loss function of the modelÂ is square error, its total error can be decomposed as:Â 
ğ¸ğ‘Ÿğ‘Ÿ(ğ‘¥ğ‘–)=Bias2+Variance+IrreducibleÂ ErrorErr(xiâ€‹)=Bias2+Variance+IrreducibleÂ Error
We skip the deductionÂ process for the above formula, but one can refer toÂ the page hereÂ for more details.
From the above definitions, we can see that a good learner should have low bias and also low variance. However, it is difficultÂ to have them both, since these two properties are contradicting to each other. As a result, one needs toÂ find the sweet spot on the model complexity in order toÂ obtain the best result.Â 
Given a learner, often one can adjust its bias and variance, by tuning the parameters involved in the learner.
For example, if we construct a decision tree for a classification problem, without any constraint the decision tree could overgrow itself to fit every bit of the training data set, including the noisyÂ data. As a result, we might obtain a decision tree model with a low bias for the given training data set. However, it could end up with high bias as well as high variance for the unseen data sets, since itÂ overfitsÂ the training data set. To mitigate the problem, one can impose some constraints to limit the growth of a decision tree,Â e.g.Â setting theÂ max depth a tree can grow, which mightÂ result in higher bias in the training data set. In exchange, we could obtain a model with lower variance in the unseen data set, as well as lower bias, since the model is trained to be more generalized.Â 
Â 
Conclusion

In this article, we clarify the notions of bias and variance, which are the characteristics associated with a learner (i.e.Â a machine learning algorithm). These characteristics are exhibited in the scenarios of applying the learner to solve a particular machine learning problem. Therefore,Â to measure the bias and variance, one should apply the learner in a set of training datasets for a given problem.
The bias and variance of a learner are defined under the context of the problem,Â i.e.Â the training data sets, the learning task and the loss functionÂ etc.Â which vary from problem to problem.Â In general, it is not fair to say that a learner is of high bias or of high variance, without mentioning the context. For example,Â the linear regression algorithm might be a terrible learner (high bias and high variance) for the image classification problems, while it could excel in someÂ simpleÂ classification problems whose data sets contain only aÂ few attributes.
Given a problem, the bias and variance ofÂ a learner is often not fixed either. One could tune the parameters with the learner to strike a balance between the bias and variance. Overall, when the complexity of the models produced by a learner increases,Â the bias of the learner decreases, while itsÂ variance increases.
Finally, let's conclude the article with the statement that we put atÂ the beginning:
Bias is a learnerâ€™s tendency to consistently learn the same wrong thing. Variance is the tendency to learn random things unrelated to the real signal [1].
Now, ifÂ youÂ haveÂ reached this point, you should be able to make sense of the statement. If you have any doubts or questions, feel free to pose in theÂ DiscussionÂ forum.
Â Â Why Machine Learning
Report Issue

After the previous chapters, one shouldÂ be able to tell in generalÂ whatÂ Machine Learning (ML) algorithms are, and should have a brief idea onÂ howÂ to apply ML in a project.
Now, in this chapter, it wouldÂ be the right momentÂ to reflect a bit more on the question:Â whyÂ do we need ML algorithms ?Â 
First of all, let's acknowledge that at this moment (2018) we do need the ML algorithms in many aspects of our lives. Noticeably, it is omnipresent in the Internet services (e.g.Â social networking, search engineÂ etc.)Â that we are indulging daily. In fact, as revealed in aÂ recent paper from Facebook,Â ML algorithms become so important that Facebook started to redesign their datacenters from hardware to software, to better cater to the requirements of applying ML algorithms.Â 
"At Facebook, machine learning provides key capabilities in driving nearly all aspects of user experiences... Machine learning is applied pervasively across nearly all services."Â Â 
Here are a few examples of how ML is applied in Facebook:
ï‚·Ranking of stories in the News Feed is done via ML.
ï‚·When, where and who to display Ads is determined by ML.
ï‚·The various search engines (e.g.Â photos, videos, people) are each powered by ML.
One could easily identify many other scenarios where ML is applied, in the services (e.g.Â Google search engine, Amazon e-commerce platform)Â that we are using nowadays. The ubiquitous presence of ML algorithms becomes a norm in the modern life, which justifies its raison d'etre at least for the moment and the near future to come.
Why ML ?
ML algorithms exist, because they can solve problems that non-ML algorithms are not able to, andÂ because they offer advantages that non-ML algorithms do not have.
One of the most important characteristics that tells a ML algorithm apart from non-ML ones, is that it decouples the model from the data so that a ML algorithm can adapt to different business scenarios or the same business case but with different contexts. For instance, a classification algorithm can be applied to tell if there is a face shown on a photo. It can also be applied to predict if users are going to click on an Ads. In the case of face detection, the same classification algorithm can be used to train a model that can tell whether or not there is a face presented on a photo, as well as training another model that tell precisely who is presented on the photo.
ThroughÂ the separation of model and data, ML algorithms can solve many problems in a moreÂ flexible,Â genericÂ andÂ autonomousÂ manner,Â i.e.Â much like a human, the ML algorithms seemÂ to be able toÂ learnÂ from the environment (i.e.Â the data)Â and adjustÂ its behaviors (i.e.Â the model) accordingly in order to solve a specific problem. Without explicitly coding the rules (i.e.Â the model) in the ML algorithms, we construct a sort of meta-algorithm that is able toÂ learnÂ the rules/patterns from the data, in a supervised or even unsupervised manner.
ML, Silver Bullet ?
Report Issue

Once one starts to learn various kinds of Machine Learning (ML) algorithms, and how versatile they are to handle challenging tasks such as image recognition and language translationÂ etc, one mightÂ be indulged to apply ML to every problem that they face, regardless of whether it fits or not. Because often the case, once one acquires a hammer, every problem might seem to be just anotherÂ nail.Â 
As a result, in this section, we would like to stress on some negative notes ofÂ ML.Â Like all other solutions, MLÂ isÂ no silver bullet.Â 
Like humans, ML models make mistakes.
For instance, oneÂ might noticeÂ that sometimes Facebook fails to tag a face from a photo. Unfortunately, people seem to accept the current state-of-the-artÂ that ML algorithm is usually notÂ 100%100%Â accurate. One can probably defend for ML algorithms, withÂ the argument that the problems that ML deals with are indeed difficult, even for humans,Â e.g.Â image recognition. However, it is contrasting to the general conceptionÂ that machines make no mistake or at least lessÂ than humans. For a moment (before 2012), people could easily claimÂ the championship ofÂ ImageNetÂ challenge with a modelÂ ofÂ 75%75%Â accuracy. One should bear in mind that the challenge was considered to the Olympic game in the domain of image recognition. So one can consider the results in ImageNet challenge as theÂ state-of-the-artÂ in the domain.Â Yet till now (2018), still no model can achieveÂ 100%100%Â of accuracy. In general, a ML model that can reach ~80%80%Â accuracy, is considered to have a decent performance.Â Therefore, in the scenarios where the accuracy of the algorithm is critical, one should carefully examineÂ their decisionÂ of adopting ML algorithms.
It is hard, if not impossible, to correct the mistakes made by ML, in theÂ case-by-case manner.
One might wonder, if we consider each mistake made by a ML model as a bug in the software, can't we just correct them one by one so that we can boost the accuracy step by step? The answer is no. The reason is twofold:Â 1).Â In general, one does not explicitlyÂ manipulate aÂ ML model, but apply a ML algorithm with a given data to generate a model. To improve a model, we either improve the algorithm or the quality of data, without modifying the model directly.Â 2).Â Even we can manipulate a generated ML model afterward, it is not intuitiveÂ how one can change the output of the ML model in certain 'erroneous' cases, without impacting the other correct cases. For instance, for a decision-tree model, the output of the model is the conjunction of branching conditions at each node, following the path from root to leaf. One can change certain branching conditions in the nodes to alter the decision of erroneousÂ cases. However, this change would also impact the outputs for every case that passes through the modified nodes. In summary, one can not treat the mistakes made by a ML model simply as bugs in the software.Â It requires a holistic approach to improve the model, rather than patching the model case by case.
It is hard, if not impossible, to reason aboutÂ certain ML models.Â 
So far, one has learnedÂ that ML model makes mistakes and it is hard to correct the mistakes case by case. Perhaps things aren't so bad, since at least we could explain why it makes mistakes, such asÂ the decision-tree model. Yet, in some cases, particularly for the ML models with neural networks, we cannot really reason about the models,Â i.e.Â it is hard to interpret the model, to identify the key parameters within a model. For instance, there is a state-of-the-art neural network model calledÂ ResNetÂ [1]Â which achievesÂ 96.43%96.43%Â accuracy in theÂ ImageNetÂ challenge. The ResNet-50 model consists of 50 layers of neurons, including 25.6 million ofÂ parameters in total. Each of the parameters contributes to the final output of the model. Either the output is correct or not, it is the millions of parameters behind the model thatÂ accounts for. It is hard to attribute any logic to each of the parameters individually.Â Therefore, in the scenarios where one looks for interpretability for the model, one should think over the decision to apply any neural-network-based ML model.
So to summarise, ML is no silver bullet, because it is often notÂ 100%100%Â accurate, and we cannot correct the ML modelÂ case by case, and in certain cases we cannot even reason about the ML models.
