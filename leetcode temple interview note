https://leetcode.com/explore/interview/card/cheatsheets/720/resources/4725/

Code templates

def fn(arr):
    left = ans = 0
    right = len(arr) - 1

    while left < right:
        # do some logic here with left and right
        if CONDITION:
            left += 1
        else:
            right -= 1
    
    return ans


def fn(arr1, arr2):
    i = j = ans = 0

    while i < len(arr1) and j < len(arr2):
        # do some logic here
        if CONDITION:
            i += 1
        else:
            j += 1
    
    while i < len(arr1):
        # do logic
        i += 1
    
    while j < len(arr2):
        # do logic
        j += 1
    
    return ans


def fn(arr):
    left = ans = curr = 0

    for right in range(len(arr)):
        # do logic here to add arr[right] to curr

        while WINDOW_CONDITION_BROKEN:
            # remove arr[left] from curr
            left += 1

        # update ans
    
return ans

def fn(arr):
    prefix = [arr[0]]
    for i in range(1, len(arr)):
        prefix.append(prefix[-1] + arr[i])
    
    return prefix

# arr is a list of characters
def fn(arr):
    ans = []
    for c in arr:
        ans.append(c)
    
    return "".join(ans)

def fn(head):
    slow = head
    fast = head
    ans = 0

    while fast and fast.next:
        # do logic
        slow = slow.next
        fast = fast.next.next
    
    return ans

def fn(head):
    curr = head
    prev = None
    while curr:
        next_node = curr.next
        curr.next = prev
        prev = curr
        curr = next_node 
        
    return prev

from collections import defaultdict

def fn(arr, k):
    counts = defaultdict(int)
    counts[0] = 1
    ans = curr = 0

    for num in arr:
        # do logic to change curr
        ans += counts[curr - k]
        counts[curr] += 1
    
    return ans

def fn(arr):
    stack = []
    ans = 0

    for num in arr:
        # for monotonic decreasing, just flip the > to <
        while stack and stack[-1] > num:
            # do logic
            stack.pop()
        stack.append(num)
    
    return ans

def dfs(root):
    if not root:
        return
    
    ans = 0

    # do logic
    dfs(root.left)
    dfs(root.right)
    return ans

def dfs(root):
    stack = [root]
    ans = 0

    while stack:
        node = stack.pop()
        # do logic
        if node.left:
            stack.append(node.left)
        if node.right:
            stack.append(node.right)

    return ans

from collections import deque

def fn(root):
    queue = deque([root])
    ans = 0

    while queue:
        current_length = len(queue)
        # do logic for current level

        for _ in range(current_length):
            node = queue.popleft()
            # do logic
            if node.left:
                queue.append(node.left)
            if node.right:
                queue.append(node.right)

    return ans

def fn(graph):
    def dfs(node):
        ans = 0
        # do some logic
        for neighbor in graph[node]:
            if neighbor not in seen:
                seen.add(neighbor)
                ans += dfs(neighbor)
        
        return ans

    seen = {START_NODE}
    return dfs(START_NODE)

def fn(graph):
    stack = [START_NODE]
    seen = {START_NODE}
    ans = 0

    while stack:
        node = stack.pop()
        # do some logic
        for neighbor in graph[node]:
            if neighbor not in seen:
                seen.add(neighbor)
                stack.append(neighbor)
    
    return ans

from collections import deque

def fn(graph):
    queue = deque([START_NODE])
    seen = {START_NODE}
    ans = 0

    while queue:
        node = queue.popleft()
        # do some logic
        for neighbor in graph[node]:
            if neighbor not in seen:
                seen.add(neighbor)
                queue.append(neighbor)
    
    return ans

import heapq

def fn(arr, k):
    heap = []
    for num in arr:
        # do some logic to push onto heap according to problem's criteria
        heapq.heappush(heap, (CRITERIA, num))
        if len(heap) > k:
            heapq.heappop(heap)
    
    return [num for num in heap]

def fn(arr, target):
    left = 0
    right = len(arr) - 1
    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            # do something
            return
        if arr[mid] > target:
            right = mid - 1
        else:
            left = mid + 1
    
    # left is the insertion point
    return left

def fn(arr, target):
    left = 0
    right = len(arr)
    while left < right:
        mid = (left + right) // 2
        if arr[mid] >= target:
            right = mid
        else:
            left = mid + 1

    return left

def fn(arr, target):
    left = 0
    right = len(arr)
    while left < right:
        mid = (left + right) // 2
        if arr[mid] > target:
            right = mid
        else:
            left = mid + 1

    return left

def fn(arr):
    def check(x):
        # this function is implemented depending on the problem
        return BOOLEAN

    left = MINIMUM_POSSIBLE_ANSWER
    right = MAXIMUM_POSSIBLE_ANSWER
    while left <= right:
        mid = (left + right) // 2
        if check(mid):
            right = mid - 1
        else:
            left = mid + 1
    
    return left

def fn(arr):
    def check(x):
        # this function is implemented depending on the problem
        return BOOLEAN

    left = MINIMUM_POSSIBLE_ANSWER
    right = MAXIMUM_POSSIBLE_ANSWER
    while left <= right:
        mid = (left + right) // 2
        if check(mid):
            left = mid + 1
        else:
            right = mid - 1
    
    return right

def backtrack(curr, OTHER_ARGUMENTS...):
    if (BASE_CASE):
        # modify the answer
        return
    
    ans = 0
    for (ITERATE_OVER_INPUT):
        # modify the current state
        ans += backtrack(curr, OTHER_ARGUMENTS...)
        # undo the modification of the current state
    
    return ans

def fn(arr):
    def dp(STATE):
        if BASE_CASE:
            return 0
        
        if STATE in memo:
            return memo[STATE]
        
        ans = RECURRENCE_RELATION(STATE)
        memo[STATE] = ans
        return ans

    memo = {}
    return dp(STATE_FOR_WHOLE_INPUT)

# note: using a class is only necessary if you want to store data at each node.
# otherwise, you can implement a trie using only hash maps.
class TrieNode:
    def __init__(self):
        # you can store data at nodes if you wish
        self.data = None
        self.children = {}

def fn(words):
    root = TrieNode()
    for word in words:
        curr = root
        for c in word:
            if c not in curr.children:
                curr.children[c] = TrieNode()
            curr = curr.children[c]
        # at this point, you have a full word at curr
        # you can perform more logic here to give curr an attribute if you want
    
    return root

from math import inf
from heapq import *

distances = [inf] * n
distances[source] = 0
heap = [(0, source)]

while heap:
    curr_dist, node = heappop(heap)
    if curr_dist > distances[node]:
        continue
    
    for nei, weight in graph[node]:
        dist = curr_dist + weight
        if dist < distances[nei]:
            distances[nei] = dist
            heappush(heap, (dist, nei))

Stages of an interviewReport Issue

Most algorithmic interview rounds are between 45 - 60 minutes. The interviews can be broken down into stages, and at each stage, there are multiple things you should do to maximize your chances of success. Let's break it down.
1. Introductions
At the start of the interview, most of the time your interviewer will briefly introduce themselves and their role at the company, then ask you to introduce yourself.
ï‚·Prepare and rehearse a brief introduction of yourself. It should summarize your education, work experience, and interests in 30-60 seconds.
ï‚·Smile and speak with a confident voice.
ï‚·When the interviewer is talking about their work at the company, pay attention - it will help to ask questions about it later.
ï‚·If the interviewer mentioned anything that you are also interested in, whether it be their work or a hobby, mention it.

2. Problem statement
After introductions, your interviewer will give you a problem statement. If you're working in a shared text editor, they will most likely paste the problem description along with a test case into the editor, and then read the question to you.
ï‚·Make sure you fully understand the problem. After the interviewer has read the problem over, confirm what the problem is asking by paraphrasing it back to them.
ï‚·
Ask clarifying questions regarding the input, for example:
ï‚·
oWill the input only have integers, or could there be other types?
oWill the input be sorted or unsorted?
oIs the input guaranteed to have elements or could it be empty?
oWhat should I do if an invalid input is given?
ï‚·
Ask about the expected input size. Sometimes, the interviewer will be vague, but if they do give you a range, it can be a clue. For example, ifÂ nÂ is very small, it is likely backtracking. IfÂ nÂ is aroundÂ 100 - 1000, anÂ ð‘‚(ð‘›2)O(n2)Â solution might be optimal. IfÂ nÂ is very large, then you might need to do better thanÂ ð‘‚(ð‘›)O(n).
ï‚·
ï‚·The interviewer will likely give you one or two example test cases. Quickly walk through one to confirm that you understand the problem.
Asking clarifying questions not only helps you better understand the problem but also shows attention to detail and being considerate of things like edge cases.

3. Brainstorming DS&A
Try to figure out what data structure or algorithm is applicable. Break the problem down and try to find common patterns that you've learned. Figure out what the problem needs you to do, and think about what data structure or algorithm can accomplish it with a good time complexity.
Think out loud. It will show your interviewer that you are good at considering tradeoffs. If the problem involves looking at subarrays, then be vocal about considering a sliding window because every window represents a subarray. Even if you're wrong, the interviewer will still appreciate your thought process.
The best way to train this skill is to practice LeetCode problems.
By thinking out loud, you also open the door for the interviewer to give you hints and point you in the right direction.
Once you have decided on what data structures/algorithms to use, you now need to construct your actual algorithm. Before coding, you should think of the rough steps of the algorithm, explain them to the interviewer, and make sure they understand and agree that it is a reasonable approach. Usually, if you are on the wrong path, they will subtly hint at it.
It isÂ extremelyÂ important that you are receptive to what the interviewer says at this stage. Remember: they know the optimal solution. If they are giving you a hint, it is because they want you to succeed. Don't be stubborn and be ready to explore the ideas they give you.

4. Implementation
Once you have come up with an algorithm and gotten the interviewer on board, it is time to start writing code.
ï‚·If you intend on using a library or module like Python's collections for example, make sure the interviewer is ok with it before importing it.
ï‚·As you implement, explain your decision-making. For example, if you are solving a graph problem, when you declare a setÂ seen, explain that it is to prevent visiting the same node more than once, thus also preventing cycles.
ï‚·Write clean code. Every major programming language has a convention for how code should be written. Make sure you know the basics of the language that you plan to be using. Google providesÂ a summaryÂ for all major languages. The most important sections are case conventions, indentations, spacing, and global variables.
ï‚·Avoid duplicated code. For example, if you are doing a DFS on a matrix, loop over a directions arrayÂ [(0, 1), (1, 0), (0, -1), (-1, 0)]Â instead of writing the same logic 4 times for each direction. If you find yourself writing similar code in multiple places, consider creating a function or simplifying it with a loop.
ï‚·Don't be scared of using helper functions. They make your code more modular, which is very important in real software engineering. It might also make potential follow-ups easier.
Don't panic if you get stuck or realize that your original plan might not work. Communicate your concerns with your interviewer. It makes their life a lot harder if you are struggling in silence.
One strategy is to first implement a brute force solutionÂ while acknowledgingÂ that it is a suboptimal solution. Once it is completed, analyze each part of the algorithm, figure out what steps are "slow", and try to think about how it can be sped up. Engage your interviewer and include them in the discussion - they want to help.

5. Testing & debugging
Once you have finished coding, your interviewer will likely want to test your code. Depending on the company, there are a few different environments your interview might be taking place in:
ï‚·
Built-in test cases, code is run
ï‚·
oThese platforms are similar to LeetCode. There will be a wide variety of test cases - small inputs, huge inputs, inputs that test edge cases.
oThis environment puts the most stress on your code because a non-perfect solution will be exposed.
oHowever, it also puts the least stress on creating your own tests, since they are already built-in.
ï‚·
Write your own test cases, code is run
ï‚·
oThese platforms are usually shared text editors that support running code. The interviewer will want you to write your own test cases.
oTo actually test the code, you should write in the outermost scope of the code, wherever the code will get run first. Assuming you solved the problem in a function (like on LeetCode), you can call your function with the test cases you wrote and print the results to the console.
oWhen writing your own tests, make sure to try a variety. Include edge cases, intuitive inputs, and possibly invalid inputs (if the interviewer wants you to handle that case).
ï‚·
Write your own test cases, code is not run
ï‚·
oThese platforms will just be shared text editors that do not support running code. The interviewer will want you to write your own test cases and walk through them manually.
oTo "test" the code, you will have to go through the algorithm manually with each test case. Try to condense trivial parts - for example, if you're creating a prefix sum, don'tÂ literallyÂ walk through the for loop with every element. Say something along the lines of "after this for loop, we will have a prefix sum which will look like ...".
oAs you are walking through the code, write (in the editor, outside your function somewhere) the variables used in the function and continuously update them.
Regardless of the scenario, if it turns out your code has an error, don't panic! If the environment supports running code, put print statements in relevant locations to try to identify the issue. Walk through a test case manually (as you would if you have an environment without runtime support) with a small test case. As you do it, talk about what the expected values of the variables should be and compare them with what they actually are. Again, the more vocal you are, the easier it is for the interviewer to help you.

6. Explanations and follow-ups
After coding the algorithm and running through test cases, be prepared to answer questions regarding your algorithm. Questions you should always expect and be ready for include:
ï‚·What is the time and space complexity of the algorithm?
oYou should speak in terms of the worst-case scenario. However, if the worst case is rare and the average case has a significantly faster runtime, you should also mention this.
ï‚·Why did you choose to do ...?
oThis could be your choice of data structure, choice of algorithm, choice of for loop configurations, etc. Be prepared to explain your thought process.
ï‚·Do you think that the algorithm could be improved in terms of time or space complexity?
oIf the problem needs to look at every element in the input (let's say the input isn't sorted and you needed to find the max element), then you probably can't do better thanÂ ð‘‚(ð‘›)O(n). Otherwise, you probably can't do better thanÂ ð‘‚(logâ¡ð‘›)O(logn).
oIf the interviewer asks this, the answer isÂ usuallyÂ yes. Be careful about asserting that your algorithm is optimal - it's ok to be wrong, but it's not ok to be confidently wrong.
If there is time remaining in the interview, you may be asked an entirely new question. In that case, restart from step 2 (Problem statement). However, you may also be asked follow-ups to the question you already solved. The interviewer might introduce new constraints, ask for an improved space complexity, or any other number of things.
This section is why it is important to actually understand solutions and not just memorize them.

7. Outro
The interviewer will usually reserve a few minutes at the end of the interview to allow you to ask questions about them or the company. You will rarely be able to improve the outcome of the interview at this point, but you can certainly make it worse.
Interviews are a two-way street. You should use this time as an opportunity to also get to know the company and see if you would like to work there. You should prepare some questions before the interview, such as:
ï‚·What does an average day look like?
ï‚·Why did you decide to join this company instead of another one?
ï‚·What is your favorite and least favorite thing about the job?
ï‚·What kind of work can I expect to work on?
All big companies will have their own tech blog. A great way to demonstrate your interest in the company is to read some blog posts and compile a list of questions regarding why the company makes the decisions they do.
Be interested, keep smiling, listen to the interviewer's responses, and ask follow-up questions to show that you understand their answers.
If you don't have quality questions or appear bored/uninterested, it could give a bad signal to the interviewer. It doesn't matter how well you did on the technical portion if the interviewer doesn't like you in the end.
This article will be a collection of cheat sheets that you can use as you solve problems and prepare for interviews. You will find:
ï‚·Time complexity (Big O) cheat sheet
ï‚·General DS/A flowchart (when to use each DS/A)
ï‚·Stages of an interview cheat sheet

Time complexity (Big O) cheat sheet

First, let's talk about the time complexity of common operations, split by data structure/algorithm. Then, we'll talk about reasonable complexities given input sizes.
Arrays (dynamic array/list)
GivenÂ n = arr.length,
ï‚·Add or remove element at the end:Â ð‘‚(1)O(1)Â amortized
ï‚·Add or remove element from arbitrary index:Â ð‘‚(ð‘›)O(n)
ï‚·Access or modify element at arbitrary index:Â ð‘‚(1)O(1)
ï‚·Check if element exists:Â ð‘‚(ð‘›)O(n)
ï‚·Two pointers:Â ð‘‚(ð‘›â‹…ð‘˜)O(nâ‹…k), whereÂ ð‘˜kÂ is the work done at each iteration, includes sliding window
ï‚·Building a prefix sum:Â ð‘‚(ð‘›)O(n)
ï‚·Finding the sum of a subarray given a prefix sum:Â ð‘‚(1)O(1)

Strings (immutable)
GivenÂ n = s.length,
ï‚·Add or remove character:Â ð‘‚(ð‘›)O(n)
ï‚·Access element at arbitrary index:Â ð‘‚(1)O(1)
ï‚·Concatenation between two strings:Â ð‘‚(ð‘›+ð‘š)O(n+m), whereÂ ð‘šmÂ is the length of the other string
ï‚·Create substring:Â ð‘‚(ð‘š)O(m), whereÂ ð‘šmÂ is the length of the substring
ï‚·Two pointers:Â ð‘‚(ð‘›â‹…ð‘˜)O(nâ‹…k), whereÂ ð‘˜kÂ is the work done at each iteration, includes sliding window
ï‚·Building a string from joining an array, stringbuilder, etc.:Â ð‘‚(ð‘›)O(n)

Linked Lists
GivenÂ ð‘›nÂ as the number of nodes in the linked list,
ï‚·Add or remove element given pointer before add/removal location:Â ð‘‚(1)O(1)
ï‚·Add or remove element given pointer at add/removal location:Â ð‘‚(1)O(1)Â if doubly linked
ï‚·Add or remove element at arbitrary position without pointer:Â ð‘‚(ð‘›)O(n)
ï‚·Access element at arbitrary position without pointer:Â ð‘‚(ð‘›)O(n)
ï‚·Check if element exists:Â ð‘‚(ð‘›)O(n)
ï‚·Reverse between positionÂ iÂ andÂ j:Â ð‘‚(ð‘—âˆ’ð‘–)O(jâˆ’i)
ï‚·Detect a cycle:Â ð‘‚(ð‘›)O(n)Â using fast-slow pointers or hash map

Hash table/dictionary
GivenÂ n = dic.length,
ï‚·Add or remove key-value pair:Â ð‘‚(1)O(1)
ï‚·Check if key exists:Â ð‘‚(1)O(1)
ï‚·Check if value exists:Â ð‘‚(ð‘›)O(n)
ï‚·Access or modify value associated with key:Â ð‘‚(1)O(1)
ï‚·Iterate over all keys, values, or both:Â ð‘‚(ð‘›)O(n)
Note: theÂ ð‘‚(1)O(1)Â operations are constant relative toÂ n. In reality, the hashing algorithm might be expensive. For example, if your keys are strings, then it will costÂ ð‘‚(ð‘š)O(m)Â whereÂ ð‘šmÂ is the length of the string. The operations only take constant time relative to the size of the hash map.

Set
GivenÂ n = set.length,
ï‚·Add or remove element:Â ð‘‚(1)O(1)
ï‚·Check if element exists:Â ð‘‚(1)O(1)
The above note applies here as well.

Stack
Stack operations are dependent on their implementation. A stack is only required to support pop and push. If implemented with a dynamic array:
GivenÂ n = stack.length,
ï‚·Push element:Â ð‘‚(1)O(1)
ï‚·Pop element:Â ð‘‚(1)O(1)
ï‚·Peek (see element at top of stack):Â ð‘‚(1)O(1)
ï‚·Access or modify element at arbitrary index:Â ð‘‚(1)O(1)
ï‚·Check if element exists:Â ð‘‚(ð‘›)O(n)

Queue
Queue operations are dependent on their implementation. A queue is only required to support dequeue and enqueue. If implemented with a doubly linked list:
GivenÂ n = queue.length,
ï‚·Enqueue element:Â ð‘‚(1)O(1)
ï‚·Dequeue element:Â ð‘‚(1)O(1)
ï‚·Peek (see element at front of queue):Â ð‘‚(1)O(1)
ï‚·Access or modify element at arbitrary index:Â ð‘‚(ð‘›)O(n)
ï‚·Check if element exists:Â ð‘‚(ð‘›)O(n)
Note: most programming languages implement queues in a more sophisticated manner than a simple doubly linked list. Depending on implementation, accessing elements by index may be faster thanÂ ð‘‚(ð‘›)O(n), orÂ ð‘‚(ð‘›)O(n)Â but with a significant constant divisor.

Binary tree problems (DFS/BFS)
GivenÂ ð‘›nÂ as the number of nodes in the tree,
Most algorithms will run inÂ ð‘‚(ð‘›â‹…ð‘˜)O(nâ‹…k)Â time, whereÂ ð‘˜kÂ is the work done at each node, usuallyÂ ð‘‚(1)O(1). This is just a general rule and not always the case. We are assuming here that BFS is implemented with an efficient queue.

Binary search tree
GivenÂ ð‘›nÂ as the number of nodes in the tree,
ï‚·Add or remove element:Â ð‘‚(ð‘›)O(n)Â worst case,Â ð‘‚(logâ¡ð‘›)O(logn)Â average case
ï‚·Check if element exists:Â ð‘‚(ð‘›)O(n)Â worst case,Â ð‘‚(logâ¡ð‘›)O(logn)Â average case
The average case is when the tree is well balanced - each depth is close to full. The worst case is when the tree is just a straight line.

Heap/Priority Queue
GivenÂ n = heap.lengthÂ and talking about min heaps,
ï‚·Add an element:Â ð‘‚(logâ¡ð‘›)O(logn)
ï‚·Delete the minimum element:Â ð‘‚(logâ¡ð‘›)O(logn)
ï‚·Find the minimum element:Â ð‘‚(1)O(1)
ï‚·Check if element exists:Â ð‘‚(ð‘›)O(n)

Binary search
Binary search runs inÂ ð‘‚(logâ¡ð‘›)O(logn)Â in the worst case, whereÂ ð‘›nÂ is the size of your initial search space.

Miscellaneous
ï‚·Sorting:Â ð‘‚(ð‘›â‹…logâ¡ð‘›)O(nâ‹…logn), whereÂ ð‘›nÂ is the size of the data being sorted
ï‚·DFS and BFS on a graph:Â ð‘‚(ð‘›â‹…ð‘˜+ð‘’)O(nâ‹…k+e), whereÂ ð‘›nÂ is the number of nodes,Â ð‘’eÂ is the number of edges, if each node is handled inÂ ð‘‚(1)O(1)Â other than iterating over edges
ï‚·DFS and BFS space complexity: typicallyÂ ð‘‚(ð‘›)O(n), but if it's in a graph, might beÂ ð‘‚(ð‘›+ð‘’)O(n+e)Â to store the graph
ï‚·Dynamic programming time complexity:Â ð‘‚(ð‘›â‹…ð‘˜)O(nâ‹…k), whereÂ ð‘›nÂ is the number of states andÂ ð‘˜kÂ is the work done at each state
ï‚·Dynamic programming space complexity:Â ð‘‚(ð‘›)O(n), whereÂ ð‘›nÂ is the number of states

Input sizes vs time complexity
The constraints of a problem can be considered as hints because they indicate an upper bound on what your solution's time complexity should be. Being able to figure out the expected time complexity of a solution given the input size is a valuable skill to have. In all LeetCode problems and most online assessments (OA), you will be given the problem's constraints. Unfortunately, you will usually not be explicitly told the constraints of a problem in an interview, but it's still good for practicing on LeetCode and completing OAs. Still, in an interview, it usually doesn't hurt to ask about the expected input sizes.

n <= 10
The expected time complexity likely has a factorial or an exponential with a base larger thanÂ 2Â -Â ð‘‚(ð‘›2â‹…ð‘›!)O(n2â‹…n!)Â orÂ ð‘‚(4ð‘›)O(4n)Â for example.
You should think about backtracking or any brute-force-esque recursive algorithm.Â n <= 10Â is extremely small and usuallyÂ anyÂ algorithm that correctly finds the answer will be fast enough.

10 < n <= 20
The expected time complexity likely involvesÂ ð‘‚(2ð‘›)O(2n). Any higher base or a factorial will be too slow (320320Â = ~3.5 billion, andÂ 20!20!Â is much larger). AÂ 2ð‘›2nÂ usually implies that given a collection of elements, you are considering all subsets/subsequences - for each element, there are two choices: take it or don't take it.
Again, this bound is very small, so most algorithms that are correct will probably be fast enough. Consider backtracking and recursion.

20 < n <= 100
At this point, exponentials will be too slow. The upper bound will likely involveÂ ð‘‚(ð‘›3)O(n3).
Problems marked as "easy" on LeetCode usually have this bound, which can be deceiving. There may be solutions that run inÂ ð‘‚(ð‘›)O(n), but the small bound allows brute force solutions to pass (finding the linear time solution might not be considered as "easy").
Consider brute force solutions that involve nested loops. If you come up with a brute force solution, try analyzing the algorithm to find what steps are "slow", and try to improve on those steps using tools like hash maps or heaps.

100 < n <= 1,000
In this range, a quadratic time complexityÂ ð‘‚(ð‘›2)O(n2)Â should be sufficient, as long as the constant factor isn't too large.
Similar to the previous range, you should consider nested loops. The difference between this range and the previous one is thatÂ ð‘‚(ð‘›2)O(n2)Â is usually the expected/optimal time complexity in this range, and it might not be possible to improve.

1,000 < n < 100,000
ð‘›<=105n<=105Â is the most common constraint you will see on LeetCode. In this range, the slowest acceptableÂ commonÂ time complexity isÂ ð‘‚(ð‘›â‹…logâ¡ð‘›)O(nâ‹…logn), although a linear time approachÂ ð‘‚(ð‘›)O(n)Â is commonly the goal.
In this range, ask yourself if sorting the input or using a heap can be helpful. If not, then aim for anÂ ð‘‚(ð‘›)O(n)Â algorithm. Nested loops that run inÂ ð‘‚(ð‘›2)O(n2)Â are unacceptable - you will probably need to make use of a technique learned in this course to simulate a nested loop's behavior inÂ ð‘‚(1)O(1)Â orÂ ð‘‚(logâ¡ð‘›)O(logn):
ï‚·Hash map
ï‚·A two pointers implementation like sliding window
ï‚·Monotonic stack
ï‚·Binary search
ï‚·Heap
ï‚·A combination of any of the above
If you have anÂ ð‘‚(ð‘›)O(n)Â algorithm, the constant factor can be reasonably large (around 40). One common theme for string problems involves looping over the characters of the alphabet at each iteration resulting in a time complexity ofÂ ð‘‚(26ð‘›)O(26n).

100,000 < n < 1,000,000
ð‘›<=106n<=106Â is a rare constraint, and will likely require a time complexity ofÂ ð‘‚(ð‘›)O(n). In this range,Â ð‘‚(ð‘›â‹…logâ¡ð‘›)O(nâ‹…logn)Â is usually safe as long as it has a small constant factor. You will very likely need to incorporate a hash map in some way.

1,000,000 < n
With huge inputs, typically in the range ofÂ 109109Â or more, the most common acceptable time complexity will be logarithmicÂ ð‘‚(logâ¡ð‘›)O(logn)Â or constantÂ ð‘‚(1)O(1). In these problems, you must either significantly reduce your search space at each iteration (usually binary search) or use clever tricks to find information in constant time (like with math or a clever use of hash maps).
Other time complexities are possible likeÂ ð‘‚(ð‘›)O(nâ€‹), but this is very rare and will usually only be seen in very advanced problems.

Sorting algorithms
All major programming languages have a built-in method for sorting. It is usually correct to assume and say sorting costsÂ ð‘‚(ð‘›â‹…logâ¡ð‘›)O(nâ‹…logn), whereÂ ð‘›nÂ is the number of elements being sorted. For completeness, here is a chart that lists many common sorting algorithms and their completeness. The algorithm implemented by a programming language varies; for example, Python uses Timsort but in C++, the specific algorithm is not mandated and varies.

Definition of a stable sort fromÂ Wikipedia: "Stable sorting algorithms maintain the relative order of records with equal keys (i.e. values). That is, a sorting algorithm is stable if whenever there are two records R and S with the same key and with R appearing before S in the original list, R will appear before S in the sorted list."

General DS/A flowchart
Here's a flowchart that can help you figure out which data structure or algorithm should be used. Note that this flowchart is very general as it would be impossible to cover every single scenario.
Note that this flowchart only covers methods taught in LICC, and as such more advanced algorithms like Dijkstra's is excluded.


Interview stages cheat sheet
The following will be a summary of the "Stages of an interview" article. If you have a remote interview, you can print this condensed version and keep it in front of you during the interview.
Stage 1: Introductions
ï‚·Have a rehearsed 30-60 second introduction regarding your education, work experience, and interests prepared.
ï‚·Smile and speak with confidence.
ï‚·Pay attention when the interviewer talks about themselves and incorporate their work into your questions later.

Stage 2: Problem statement
ï‚·Paraphrase the problem back to the interviewer after they have read it to you.
ï‚·Ask clarifying questions about the input such as the expected input size, edge cases, and invalid inputs.
ï‚·Quickly walk through an example test case to confirm you understand the problem.

Stage 3: Brainstorming DS&A
ï‚·Always be thinking out loud.
ï‚·Break the problem down: figure out what you need to do, and think about what data structure or algorithm can accomplish it with a good time complexity.
ï‚·Be receptive to any comments or feedback from the interviewer, they are probably trying to hint you towards the correct solution.
ï‚·Once you have an idea, before coding, explain your idea to the interviewer and make sure they understand and agree that it is a reasonable approach.

Stage 4: Implementation
ï‚·Explain your decision-making as you implement. When you declare things like sets, explain what the purpose is.
ï‚·Write clean code that conforms to your programming language's conventions.
ï‚·Avoid writing duplicate code - use a helper function or for loop if you are writing similar code multiple times.
ï‚·If you are stuck, don't panic - communicate your concerns with your interviewer.
ï‚·Don't be scared to start with a brute force solution (while acknowledging that it is brute force), then improve it by optimizing the "slow" parts.
ï‚·Keep thinking out loud and talk with your interviewer. It makes it easier for them to give you hints.

Stage 5: Testing & debugging
ï‚·When walking through test cases, keep track of the variables by writing at the bottom of the file, and continuously update them. Condense trivial parts like creating a prefix sum to save time.
ï‚·If there are errors and the environment supports running code, put print statements in your algorithm and walk through a small test case, comparing the expected value of variables and the actual values.
ï‚·Be vocal and keep talking with your interviewer if you run into any problems.

Stage 6: Explanations and follow-ups
Questions you should be prepared to answer:
ï‚·Time and space complexity, average and worst case.
ï‚·Why did you choose this data structure, algorithm, or logic?
ï‚·Do you think the algorithm could be improved in terms of complexity? If they ask you this, then the answer isÂ usuallyÂ yes, especially if your algorithm is slower thanÂ ð‘‚(ð‘›)O(n).

Stage 7: Outro
ï‚·Have questions regarding the company prepared.
ï‚·Be interested, smile, and ask follow-up questions to your interviewer's responses.
