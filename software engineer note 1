https://web2.qatar.cmu.edu/cs/17313/Software-Engineering-9th-Edition-by-Ian-Sommerville.pdf


Software engineering is an engineering discipline that is concerned with all aspects of software production. ■ Software is not just a program or programs but also includes documentation. Essential software product attributes are maintainability, dependability, security, efficiency, and acceptability. ■ The software process includes all of the activities involved in software development. The highlevel activities of specification, development, validation, and evolution are part of all software processes. ■ The fundamental notions of software engineering are universally applicable to all types of system development. These fundamentals include software processes, dependability, security, requirements, and reuse. ■ There are many different types of systems and each requires appropriate software engineering tools and techniques for their development. There are few, if any, specific design and implementation techniques that are applicable to all kinds of systems. ■ The fundamental ideas of software engineering are applicable to all types of software systems. These fundamentals include managed software processes, software dependability and security, requirements engineering, and software reuse. ■ Software engineers have responsibilities to the engineering profession and society. They should not simply be concerned with technical issues. ■ Professional societies publish codes of conduct that set out the standards of behavior expected of their members.

1.Software specification The functionality of the software and constraints on its operation must be defined. 2. Software design and implementation The software to meet the specification must be produced. 3. Software validation The software must be validated to ensure that it does what the customer wants. 4. Software evolution The software must evolve to meet changing customer needs.
. Requirements analysis and definition The system’s services, constraints, and goals are established by consultation with system users. They are then defined in detail and serve as a system specification. 2. System and software design The systems design process allocates the requirements to either hardware or software systems by establishing an overall system architecture. Software design involves identifying and describing the fundamental software system abstractions and their relationships. 3. Implementation and unit testing During this stage, the software design is realized as a set of programs or program units. Unit testing involves verifying that each unit meets its specification. 4. Integration and system testing The individual program units or programs are integrated and tested as a complete system to ensure that the software requirements have been met. After testing, the software system is delivered to the customer. 5. Operation and maintenance Normally (although not necessarily), this is the longest life cycle phase. The system is installed and put into practical use. Maintenance involves correcting errors which were not discovered in earlier stages of the life cycle, improving the implementation of system units and enhancing the system’s services as new requirements are discovered


Component analysis Given the requirements specification, a search is made for components to implement that specification. Usually, there is no exact match and the components that may be used only provide some of the functionality required. 2. Requirements modification During this stage, the requirements are analyzed using information about the components that have been discovered. They are then modified to reflect the available components. Where modifications are impossible, the component analysis activity may be re-entered to search for alternative solutions. 3. System design with reuse During this phase, the framework of the system is designed or an existing framework is reused. The designers take into account the components that are reused and organize the framework to cater for this. Some new software may have to be designed if reusable components are not available. 4. Development and integration Software that cannot be externally procured is developed, and the components and COTS systems are integrated to create the new system. System integration, in this model, may be part of the development process rather than a separate activity.

Business modelling The business processes are modelled using business use cases. Requirements Actors who interact with the system are identified and use cases are developed to model the system requirements. Analysis and design A design model is created and documented using architectural models, component models, object models, and sequence models. Implementation The components in the system are implemented and structured into implementation sub-systems. Automatic code generation from design models helps accelerate this process. Testing Testing is an iterative process that is carried out in conjunction with implementation. System testing follows the completion of the implementation. Deployment A product release is created, distributed to users, and installed in their workplace. Configuration and change management This supporting workflow manages changes to the system (see Chapter 25). Project management This supporting workflow manages the system development (see Chapters 22 and 23). Environment This workflow is concerned with making appropriate software tools available to the software development team


Software processes are the activities involved in producing a software system. Software process models are abstract representations of these processes. ■ General process models describe the organization of software processes. Examples of these general models include the waterfall model, incremental development, and reuse-oriented development. ■ Requirements engineering is the process of developing a software specification. Specifications are intended to communicate the system needs of the customer to the system developers. ■ Design and implementation processes are concerned with transforming a requirements specification into an executable software system. Systematic design methods may be used as part of this transformation. ■ Software validation is the process of checking that the system conforms to its specification and that it meets the real needs of the users of the system. ■ Software evolution takes place when you change existing software systems to meet new requirements. Changes are continuous and the software must evolve to remain useful. ■ Processes should include activities to cope with change. This may involve a prototyping phase that helps avoid poor decisions on requirements and design. Processes may be structured for iterative development and delivery so that changes may be made without disrupting the system as a whole. ■ The Rational Unified Process is a modern generic process model that is organized into phases (inception, elaboration, construction, and transition) but separates activities (requirements, analysis, and design, etc.) from these phases.

We are uncovering better ways of developing software by doing it and helping others do it. Through this work we have come to value: Individuals and interactions over processes and tools Working software over comprehensive documentation Customer collaboration over contract negotiation Responding to change over following a plan That is, while there is value in the items on the right, we value the items on the left more

Customer involvement Customers should be closely involved throughout the development process. Their role is provide and prioritize new system requirements and to evaluate the iterations of the system. Incremental delivery The software is developed in increments with the customer specifying the requirements to be included in each increment. People not process The skills of the development team should be recognized and exploited. Team members should be left to develop their own ways of working without prescriptive processes. Embrace change Expect the system requirements to change and so design the system to accommodate these changes. Maintain simplicity Focus on simplicity in both the software being developed and in the development process. Wherever possible, actively work to eliminate complexity from the system

Agile methods are incremental development methods that focus on rapid development, frequent releases of the software, reducing process overheads, and producing high-quality code. They involve the customer directly in the development process. ■ The decision on whether to use an agile or a plan-driven approach to development should depend on the type of software being developed, the capabilities of the development team, and the culture of the company developing the system. ■ Extreme programming is a well-known agile method that integrates a range of good programming practices such as frequent releases of the software, continuous software improvement, and customer participation in the development team. ■ A particular strength of extreme programming is the development of automated tests before a program feature is created. All tests must successfully execute when an increment is integrated into a system.

The Scrum method is an agile method that provides a project management framework. It is centered around a set of sprints, which are fixed time periods when a system increment is developed. Planning is based on prioritizing a backlog of work and selecting the highestpriority tasks for a sprint. ■ Scaling agile methods for large systems is difficult. Large systems need up-front design and some documentation. Continuous integration is practically impossible when there are several separate development teams working on a project.

Objectives The objective of this chapter is to introduce software requirements and to discuss the processes involved in discovering and documenting these requirements. When you have read the chapter you will: ■ understand the concepts of user and system requirements and why these requirements should be written in different ways; ■ understand the differences between functional and nonfunctional software requirements; ■ understand how requirements may be organized in a software requirements document; ■ understand the principal requirements engineering activities of elicitation, analysis and validation, and the relationships between these activities; ■ understand why requirements management is necessary and how it supports other requirements engineering activities.

Requirements for a software system set out what the system should do and define constraints on its operation and implementation. ■ Functional requirements are statements of the services that the system must provide or are descriptions of how some computations must be carried out. ■ Non-functional requirements often constrain the system being developed and the development process being used. These might be product requirements, organizational requirements, or external requirements. They often relate to the emergent properties of the system and therefore apply to the system as a whole. ■ The software requirements document is an agreed statement of the system requirements. It should be organized so that both system customers and software developers can use it. ■ The requirements engineering process includes a feasibility study, requirements elicitation and analysis, requirements specification, requirements validation, and requirements management. ■ Requirements elicitation and analysis is an iterative process that can be represented as a spiral of activities—requirements discovery, requirements classification and organization, requirements negotiation, and requirements documentation. ■ Requirements validation is the process of checking the requirements for validity, consistency, completeness, realism, and verifiability. ■ Business, organizational, and technical changes inevitably lead to changes to the requirements for a software system. Requirements management is the process of managing and controlling these changes.

■ A model is an abstract view of a system that ignores some system details. Complementary system models can be developed to show the system’s context, interactions, structure, and behavior. ■ Context models show how a system that is being modeled is positioned in an environment with other systems and processes. They help define the boundaries of the system to be developed. ■ Use case diagrams and sequence diagrams are used to describe the interactions between user the system being designed and users/other systems. Use cases describe interactions between a system and external actors; sequence diagrams add more information to these by showing interactions between system objects.
Structural models show the organization and architecture of a system. Class diagrams are used to define the static structure of classes in a system and their associations. ■ Behavioral models are used to describe the dynamic behavior of an executing system. This can be modeled from the perspective of the data processed by the system or by the events that stimulate responses from a system. ■ Activity diagrams may be used to model the processing of data, where each activity represents one process step. ■ State diagrams are used to model a system’s behavior in response to internal or external events. ■ Model-driven engineering is an approach to software development in which a system is represented as a set of models that can be automatically transformed to executable code.

A software architecture is a description of how a software system is organized. Properties of a system such as performance, security, and availability are influenced by the architecture used. ■ Architectural design decisions include decisions on the type of application, the distribution of the system, the architectural styles to be used, and the ways in which the architecture should be documented and evaluated. ■ Architectures may be documented from several different perspectives or views. Possible views include a conceptual view, a logical view, a process view, a development view, and a physical view. ■ Architectural patterns are a means of reusing knowledge about generic system architectures. They describe the architecture, explain when it may be used, and discuss its advantages and disadvantages. ■ Commonly used architectural patterns include Model-View-Controller, Layered Architecture, Repository, Client–server, and Pipe and Filter. ■ Generic models of application systems architectures help us understand the operation of applications, compare applications of the same type, validate application system designs, and assess large-scale components for reuse. ■ Transaction processing systems are interactive systems that allow information in a database to be remotely accessed and modified by a number of users. Information systems and resource management systems are examples of transaction processing systems. ■ Language processing systems are used to translate texts from one language into another and to carry out the instructions specified in the input language. They include a translator and an abstract machine that executes the generated language

Software design and implementation are interleaved activities. The level of detail in the design depends on the type of system being developed and whether you are using a plan-driven or agile approach. ■ The process of object-oriented design includes activities to design the system architecture, identify objects in the system, describe the design using different object models, and document the component interfaces. ■ A range of different models may be produced during an object-oriented design process. These include static models (class models, generalization models, association models) and dynamic models (sequence models, state machine models). ■ Component interfaces must be defined precisely so that other objects can use them. A UML interface stereotype may be used to define interfaces. ■ When developing software, you should always consider the possibility of reusing existing software, either as components, services, or complete systems.

Configuration management is the process of managing changes to an evolving software system. It is essential when a team of people are cooperating to develop software. ■ Most software development is host-target development. You use an IDE on a host machine to develop the software, which is transferred to a target machine for execution. ■ Open source development involves making the source code of a system publicly available. This means that many people can propose changes and improvements to the software.

1.Authentication by logging on to the system. 2. Downloading and uploading of specified patient records to a laptop. 3. Home visit scheduling. 4. Encryption and decryption of patient records on a mobile device. 5. Record retrieval and modification. 6. Links with the drugs database that maintains side-effect information. 7. The system for call prompting.
Testing can only show the presence of errors in a program. It cannot demonstrate that there are no remaining faults. ■ Development testing is the responsibility of the software development team. A separate team should be responsible for testing a system before it is released to customers. In the user testing process, customers or system users provide test data and check that tests are successful. ■ Development testing includes unit testing, in which you test individual objects and methods; component testing, in which you test related groups of objects; and system testing, in which you test partial or complete systems. ■ When testing software, you should try to ‘break’ the software by using experience and guidelines to choose types of test cases that have been effective in discovering defects in other systems. ■ Wherever possible, you should write automated tests. The tests are embedded in a program that can be run every time a change is made to a system. ■ Test-first development is an approach to development where tests are written before the code to be tested. Small code changes are made and the code is refactored until all tests execute successfully. ■ Scenario testing is useful because it replicates the practical use of the system. It involves inventing a typical usage scenario and using this to derive test cases. ■ Acceptance testing is a user testing process where the aim is to decide if the software is good enough to be deployed and used in its operational environment.

1.Scrap the system completely This option should be chosen when the system is not making an effective contribution to business processes. This commonly occurs when business processes have changed since the system was installed and are no longer reliant on the legacy system. 2. Leave the system unchanged and continue with regular maintenance This option should be chosen when the system is still required but is fairly stable and the system users make relatively few change requests. 3. Reengineer the system to improve its maintainability This option should be chosen when the system quality has been degraded by change and where a new change to the system is still being proposed. This process may include developing new interface components so that the original system can work with other, newer systems. 4. Replace all or part of the system with a new system This option should be chosen when factors, such as new hardware, mean that the old system cannot continue in operation or where off-the-shelf systems would allow the new system to be developed at a reasonable cost. In many cases, an evolutionary replacement strategy can be adopted in which major system components are replaced by offthe-shelf systems with other components reused wherever possible.


Software development and evolution can be thought of as an integrated, iterative process that can be represented using a spiral model. ■ For custom systems, the costs of software maintenance usually exceed the software development costs. ■ The process of software evolution is driven by requests for changes and includes change impact analysis, release planning, and change implementation. ■ Lehman’s laws, such as the notion that change is continuous, describe a number of insights derived from long-term studies of system evolution. ■ There are three types of software maintenance, namely bug fixing, modifying the software to work in a new environment, and implementing new or changed requirements. ■ Software reengineering is concerned with restructuring and redocumenting software to make it easier to understand and change. ■ Refactoring, making small program changes that preserve functionality, can be thought of as preventative maintenance. ■ The business value of a legacy system and the quality of the application software and its environment should be assessed to determine whether the system should be replaced, transformed, or maintained.

1.Procurement or acquisition During this stage, the purpose of a system is decided; high-level system requirements are established; decisions are made on how functionality will be distributed across hardware, software, and people; and the components that will make up the system are purchased. 2. Development During this stage, the system is developed. Development processes include all of the activities involved in system development such as requirements definition, system design, hardware and software engineering, system integration, and testing. Operational processes are defined and the training courses for system users are designed. 3. Operation At this stage, the system is deployed, users are trained, and the system is brought into use. The planned operational processes usually then have to change to reflect the real working environment where the system is used. Over time, the system evolves as new requirements are identified. Eventually, the system declines in value and it is decommissioned and replaced.



■ Sociotechnical systems include computer hardware, software, and people, and are situated within an organization. They are designed to support organizational or business goals and objectives. ■ Human and organizational factors such as organizational structure and politics have a significant effect on the operation of sociotechnical systems. ■ The emergent properties of a system are characteristics of the system as a whole rather than of its component parts. They include properties such as performance, reliability, usability, safety, and security. The success or failure of a system is often dependent on these emergent properties. ■ The fundamental systems engineering processes are system procurement, system development, and system operation. ■ System procurement covers all of the activities involved in deciding what system to buy and who should supply that system. High-level requirements are developed as part of the procurement process. ■ System development includes requirements specification, design, construction, integration, and testing. System integration, where subsystems from more than one supplier must be made to work together, is particularly critical. ■ When a system is put into use, the operational processes and the system itself have to change to reflect changing business requirements. ■ Human errors are inevitable and systems should include barriers to detect these errors before they lead to system failure. Reason’s Swiss cheese model explains how human error plus latent defects in the barriers can lead to system failure.


Failure of critical computer systems can lead to large economic losses, serious information loss, physical damage, or threats to human life. ■ The dependability of a computer system is a system property that reflects the user’s degree of trust in the system. The most important dimensions of dependability are availability, reliability, safety, and security. ■ The availability of a system is the probability that the system will be able to deliver services to its users when requested to do so. Reliability is the probability that system services will be delivered as specified. ■ Perceived reliability is related to the probability of an error occurring in operational use. A program may contain known faults but may still be experienced as reliable by its users. They may never use features of the system that are affected by the faults. ■ The safety of a system is a system attribute that reflects the system’s ability to operate, normally or abnormally, without injury to people or damage to the environment. ■ Security reflects the ability of a system to protect itself against external attacks. Security failures may lead to loss of availability, damage to the system or its data, or the leakage of information to unauthorized people. ■ Without a reasonable level of security, the availability, reliability, and safety of the system may be compromised if external attacks damage the system. If a system is unreliable, it is difficult to ensure system safety or security, as they may be compromised by system failures.


■ Risk analysis is an important activity in the specification of security and dependability requirements. It involves identifying risks that can result in accidents or incidents. System requirements are then generated to ensure that these risks do not occur and, if they do, that they do not lead to an incident or accident. ■ A hazard-driven approach may be used to understand the safety requirements for a system. You identify potential hazards and decompose these (using methods such as fault tree analysis) to discover their root causes. You then specify requirements to avoid or recover from these problems. ■ Reliability requirements can be defined quantitatively in the system requirements specification. Reliability metrics include probability of failure on demand (POFOD), rate of occurrence of failure (ROCOF), and availability (AVAIL).

It is important not to overspecify the required system reliability as this leads to unnecessary additional costs in the development and validation processes. ■ Security requirements are more difficult to identify than safety requirements because a system attacker can use knowledge of system vulnerabilities to plan a system attack, and can learn about vulnerabilities from unsuccessful attacks. ■ To specify security requirements, you should identify the assets that are to be protected and define how security techniques and technology should be used to protect these assets. ■ Formal methods of software development rely on a system specification that is expressed as a mathematical model. Developing a formal specification has the key benefit of stimulating a detailed examination and analysis of the system requirements.

Fault avoidance The software design and implementation process should use approaches to software development that help avoid design and programming errors and so minimize the number of faults that are likely to arise when the system is executing. Fewer faults mean less chance of run-time failures. 2. Fault detection and correction The verification and validation processes are designed to discover and remove faults in a program, before it is deployed for operational use. Critical systems require very extensive verification and validation to discover as many faults as possible before deployment and to convince the system stakeholders that the system is dependable. I cover this topic in Chapter 15. 3. Fault tolerance The system is designed so that faults or unexpected system behavior during execution are detected at run-time and are managed in such a way that system failure does not occur. Simple approaches to fault tolerance based on built-in run-time checking may be included in all systems. However, more specialized fault-tolerance techniques (such as the use of fault-tolerant system architectures) are generally only used when a very high level of system availability and reliability is required

Dependability in a program can be achieved by avoiding the introduction of faults, by detecting and removing faults before system deployment, and by including fault-tolerance facilities that allow the system to remain operational after a fault has caused a system failure. ■ The use of redundancy and diversity in hardware, software processes, and software systems is essential to the development of dependable systems. ■ The use of a well-defined, repeatable process is essential if faults in a system are to be minimized. The process should include verification and validation activities at all stages, from requirements definition through to system implementation. ■ Dependable system architectures are system architectures that are designed for fault tolerance. There are a number of architectural styles that support fault tolerance including protection systems, self-monitoring architectures, and N-version programming. ■ Software diversity is difficult to achieve because it is practically impossible to ensure that each version of the software is truly independent.

Dependable programming relies on the inclusion of redundancy in a program to check the validity of inputs and the values of program variables. ■ Some programming constructs and techniques, such as go-to statements, pointers, recursion, inheritance, and floating-point numbers, are inherently error prone. You should try to avoid these constructs when developing dependable systems.

Security guidelines 1 Base security decisions on an explicit security policy 2 Avoid a single point of failure 3 Fail securely 4 Balance security and usability 5 Log user actions 6 Use redundancy and diversity to reduce risk 7 Validate all inputs 8 Compartmentalize your assets 9 Design for deployment 10 Design for recoverability

Security engineering focuses on how to develop and maintain software systems that can resist malicious attacks intended to damage a computer-based system or its data. ■ Security threats can be threats to the confidentiality, integrity, or availability of a system or its data. ■ Security risk management involves assessing the losses that might ensue from attacks on a system, and deriving security requirements that are aimed at eliminating or reducing these losses. ■ Design for security involves designing a secure system architecture, following good practice for secure systems design, and including functionality to minimize the possibility of introducing vulnerabilities when the system is deployed. ■ Key issues when designing a secure systems architecture include organizing the system structure to protect key assets and distributing the system assets to minimize the losses from a successful attack. ■ Security design guidelines sensitize system designers to security issues that they may not have considered. They provide a basis for creating security review checklists. ■ To support secure deployment you should provide a way of displaying and analyzing system configurations, localize configuration settings so that important configurations are not forgotten, minimize default privileges assigned to system users, and provide ways to repair security vulnerabilities. ■ System survivability reflects the ability of a system to continue to deliver essential business or mission-critical services to legitimate users while it is under attack, or after part of the system has been damaged.

Static analysis is an approach to V & V that examines the source code (or other representation) of a system, looking for errors and anomalies. It allows all parts of a program to be checked, not just those parts that are exercised by system tests. ■ Model checking is a formal approach to static analysis that exhaustively checks all states in a system for potential errors. ■ Statistical testing is used to estimate software reliability. It relies on testing the system with a test data set that reflects the operational profile of the software. Test data may be generated automatically.

Security validation is difficult because security requirements state what should not happen in a system, rather than what should. Furthermore, system attackers are intelligent and may have more time to probe for weaknesses than is available for security testing. ■ Security validation may be carried out using experience-based analysis, tool-based analysis, or ‘tiger teams’ that simulate attacks on a system. ■ It is important to have a well-defined, certified process for safety-critical systems development. The process must include the identification and monitoring of potential hazards. ■ Safety and dependability cases collect all of the evidence that demonstrates a system is safe and dependable. Safety cases are required when an external regulator must certify the system before it is used. ■ Safety cases are usually based on structured arguments. Structured safety arguments show that an identified hazardous condition can never occur by considering all program paths that lead to an unsafe condition, and showing that the condition cannot hold.


System infrastructure frameworks These frameworks support the development of system infrastructures such as communications, user interfaces, and compilers (Schmidt, 1997). 2. Middleware integration frameworks These consist of a set of standards and associated object classes that support component communication and information exchange. Examples of this type of framework include Microsoft’s .NET and Enterprise Java Beans (EJB). These frameworks provide support for standardized component models, as discussed in Chapter 17. 3. Enterprise application frameworks These are concerned with specific application domains such as telecommunications or financial systems (Baumer, et al., 1997). These embed application domain knowledge and support the development of end-user applications.

1.Lack of control over functionality and performance Although the published interface of a product may appear to offer the required facilities, these may not be properly implemented or may perform poorly. The product may have hidden operations that interfere with its use in a specific situation. Fixing these problems may be a priority for the COTS product integrator but may not be of real concern for the product vendor. Users may simply have to find work-arounds to problems if they wish to reuse the COTS product. 2. Problems with COTS system interoperability It is sometimes difficult to get COTS products to work together because each product embeds its own assumptions about how it will be used. Garlan et al. (1995), reporting on their experience of trying to integrate four COTS products, found that three of these products were event-based but each used a different model of events. Each system assumed that it had exclusive access to the event queue. As a consequence, integration was very difficult. The project required five times as much effort as originally predicted. The schedule was extended to two years rather than the predicted six months. In a retrospective analysis of their work 10 years later, Garlan et al. (2009) concluded that the integration problems that they discovered had not been solved. Torchiano and Morisio (2004) found that lack of compliance with standards in some COTS products meant that integration was more difficult than anticipated. 3. No control over system evolution Vendors of COTS products make their own decisions on system changes, in response to market pressures. For PC products, in particular, new versions are often produced frequently and may not be compatible with all previous versions. New versions may have additional unwanted functionality, and previous versions may become unavailable and unsupported. 4. Support from COTS vendors The level of support available from COTS vendors varies widely. Vendor support is particularly important when problems arise as


Most new business software systems are now developed by reusing knowledge and code from previously implemented systems. ■ There are many different ways to reuse software. These range from the reuse of classes and methods in libraries to the reuse of complete application systems. ■ The advantages of software reuse are lower costs, faster software development, and lower risks. System dependability is increased. Specialists can be used more effectively by concentrating their expertise on the design of reusable components. ■ Application frameworks are collections of concrete and abstract objects that are designed for reuse through specialization and the addition of new objects. They usually incorporate good design practice through design patterns. ■ Software product lines are related applications that are developed from one or more base applications. A generic system is adapted and specialized to meet specific requirements for functionality, target platform, or operational configuration. ■ COTS product reuse is concerned with the reuse of large-scale, off-the-shelf systems. These provide a lot of functionality and their reuse can radically reduce costs and development time. Systems may be developed by configuring a single, generic COTS product or by integrating two or more COTS products. ■ Enterprise Resource Planning systems are examples of large-scale COTS reuse. You create an instance of an ERP system by configuring a generic system with information about the customer’s business processes and rules. ■ Potential problems with COTS-based reuse include lack of control over functionality and performance, lack of control over system evolution, the need for support from external vendors, and difficulties in ensuring that systems can interoperate.


Component-based software engineering is a reuse-based approach to defining, implementing, and composing loosely coupled independent components into systems. ■ A component is a software unit whose functionality and dependencies are completely defined by a set of public interfaces. Components can be composed with other components without knowledge of their implementation and can be deployed as an executable unit. ■ Components may be implemented as program units that are included in a system or as external services that are referenced from within a system. ■ A component model defines a set of standards for components, including interface standards, usage standards, and deployment standards. The implementation of the component model provides a set of common services that may be used by all components. ■ During the CBSE process, you have to interleave the processes of requirements engineering and system design. You have to trade off desirable requirements against the services that are available from existing reusable components. ■ Component composition is the process of ‘wiring’ components together to create a system. Types of composition include sequential composition, hierarchical composition, and additive composition.

When composing reusable components that have not been written for your application, you may need to write adaptors or ‘glue code’ to reconcile the different component interfaces. ■ When choosing compositions, you have to consider the required functionality of the system, the non-functional requirements and the ease with which one component can be replaced when the system is changed.

The benefits of distributed systems are that they can be scaled to cope with increasing demand, can continue to provide user services (even if some parts of the system fail), and they enable resources to be shared. ■ Issues to be considered in the design of distributed systems include transparency, openness, scalability, security, quality of service, and failure management. ■ Client–server systems are distributed systems in which the system is structured into layers, with the presentation layer implemented on a client computer. Servers provide data management, application, and database services. ■ Client–server systems may have several tiers, with different layers of the system distributed to different computers. ■ Architectural patterns for distributed systems include master-slave architectures, two-tier and multitier client–server architectures, distributed component architectures, and peer-to-peer architectures. ■ Distributed component systems require middleware to handle component communications and to allow components to be added to and removed from the system. ■ Peer-to-peer architectures are decentralized architectures in which there are no distinguished clients and servers. Computations can be distributed over many systems in different organizations. ■ Software as a service is a way of deploying applications as thin client–server systems, where the client is a web browser.


Service-oriented architecture is an approach to software engineering where reusable, standardized services are the basic building blocks for application systems. ■ Service interfaces may be defined in an XML-based language called WSDL. A WSDL specification includes a definition of the interface types and operations, the binding protocol used by the service and the service location. ■ Services may be classified as utility services that provide a general-purpose functionality, business services that implement part of a business process, or coordination services that coordinate the execution of other services. ■ The service engineering process involves identifying candidate services for implementation, defining the service interface and implementing, and testing and deploying the service. ■ Service interfaces may be defined for legacy software systems that continue to be useful for an organization. The functionality of the legacy system may then be reused in other applications. ■ The development of software using services is based around the idea that programs are created by composing and configuring services to create new composite services. ■ Business process models define the activities and information exchange that takes place in a business process. Activities in the business process may be implemented by services so that the business process model represents a service composition.

■ An embedded software system is part of a hardware/software system that reacts to events in its environment. The software is ‘embedded’ in the hardware. Embedded systems are normally real-time systems. ■ A real-time system is a software system that must respond to events in real time. System correctness does not just depend on the results it produces, but also on the time when these results are produced. ■ Real-time systems are usually implemented as a set of communicating processes that react to stimuli to produce responses. ■ State models are an important design representation for embedded real-time systems. They are used to show how the system reacts to its environment as events trigger changes of state in the system. ■ There are several standard patterns that can be observed in different types of embedded systems. These include a pattern for monitoring the system’s environment for adverse events, a pattern for actuator control and a data-processing pattern. ■ Designers of real-time systems have to do a timing analysis, which is driven by the deadlines for processing and responding to stimuli. They have to decide how often each process in the system should run and the expected and worst-case execution time for processes. ■ A real-time operating system is responsible for process and resource management. It always includes a scheduler, which is the component responsible for deciding which process should be scheduled for execution.

The main benefit of an aspect-oriented approach to software development is that it supports the separation of concerns. By representing cross-cutting concerns as aspects, individual concerns can be understood, reused, and modified without changing other parts of the program. ■ Tangling occurs when a module in a system includes code that implements different system requirements. The related phenomenon of scattering occurs when the implementation of a single concern is scattered across several components in a program. ■ Aspects include a pointcut—a statement that defines where the aspect will be woven into the program, and advice—the code to implement the cross-cutting concern. Join points are the events that can be referenced in a pointcut. ■ To ensure the separation of concerns, systems can be designed as a core system that implements the primary concerns of stakeholders, and a set of extensions that implement secondary concerns. ■ To identify concerns, you may use a viewpoint-oriented approach to requirements engineering to elicit stakeholder requirements and to identify cross-cutting quality of service and policy concerns. ■ The transition from requirements to design can be made by identifying use cases, where each use case represents a stakeholder concern. The design may be modeled using an extended version of the UML with aspect stereotypes. ■ The problems of inspecting and deriving tests for aspect-oriented programs are a significant barrier to the adoption of aspect-oriented software development in large software projects.

Good software project management is essential if software engineering projects are to be developed on schedule and within budget. ■ Software management is distinct from other engineering management. Software is intangible. Projects may be novel or innovative so there is no body of experience to guide their management. Software processes are not as mature as traditional engineering processes. ■ Risk management is now recognized as one of the most important project management tasks. ■ Risk management involves identifying and assessing major project risks to establish the probability that they will occur and the consequences for the project if that risk does arise. You should make plans to avoid, manage, or deal with likely risks if or when they arise. ■ People are motivated by interaction with other people, the recognition of management and their peers, and by being given opportunities for personal development. ■ Software development groups should be fairly small and cohesive. The key factors that influence the effectiveness of a group are the people in that group, the way that it is organized, and the communication between group members. ■ Communications within a group are influenced by factors such as the status of group members, the size of the group, the gender composition of the group, personalities, and available communication channels.

The price charged for a system does not just depend on its estimated development costs and the profit required by the development company. Organizational factors may mean that the price is increased to compensate for increased risk or decreased to gain competitive advantage. ■ Software is often priced to gain a contract and the functionality of the system is then adjusted to meet the estimated price. ■ Plan-driven development is organized around a complete project plan that defines the project activities, the planned effort, the activity schedule, and who is responsible for each activity. ■ Project scheduling involves the creation of various graphical representations of part of the project plan. Bar charts, which show the activity duration and staffing timelines, are the most commonly used schedule representations. ■ A project milestone is a predictable outcome of an activity or set of activities. At each milestone, a formal report of progress should be presented to management. A deliverable is a work product that is delivered to the project customer. ■ The XP planning game involves the whole team in project planning. The plan is developed incrementally and, if problems arise, it is adjusted so that software functionality is reduced instead of delaying the delivery of an increment. ■ Estimation techniques for software may be experience-based, where managers judge the effort required, or algorithmic, where the effort required is computed from other estimated project parameters. ■ The COCOMO II costing model is a mature algorithmic cost model that takes project, product, hardware, and personnel attributes into account when formulating a cost estimate.

Software quality management is concerned with ensuring that software has a low number of defects and that it reaches the required standards of maintainability, reliability, portability, and so on. It includes defining standards for processes and products and establishing processes to check that these standards have been followed. ■ Software standards are important for quality assurance as they represent an identification of ‘best practice’. When developing software, standards provide a solid foundation for building good quality software. ■ You should document a set of quality assurance procedures in an organizational quality manual. This may be based on the generic model for a quality manual suggested in the ISO 9001 standard. ■ Reviews of the software process deliverables involve a team of people who check that quality standards are being followed. Reviews are the most widely used technique for assessing quality. ■ In a program inspection or peer review, a small team systematically checks the code. They read the code in detail and look for possible errors and omissions. The problems detected are then discussed at a code review meeting.

Software measurement can be used to gather quantitative data about software and the software process. You may be able to use the values of the software metrics that are collected to make inferences about product and process quality. ■ Product quality metrics are particularly useful for highlighting anomalous components that may have quality problems. These components should then be analyzed in more detail.

Configuration management is the management of an evolving software system. When maintaining a system, a CM team is put in place to ensure that changes are incorporated into the system in a controlled way and that records are maintained with details of the changes that have been implemented. ■ The main configuration management processes are concerned with change management, version management, system building, and release management. Software tools are available to support all of these processes. ■ Change management involves assessing proposals for changes from system customers and other stakeholders and deciding if it is cost-effective to implement these in a new version of a system. ■ Version management involves keeping track of the different versions of software components that are created as changes are made to them. ■ System building is the process of assembling system components into an executable program to run on a target computer system. ■ Software should be frequently rebuilt and tested immediately after a new version has been built. This makes it easier to detect bugs and problems that have been introduced since the last build. ■ System releases include executable code, data files, configuration files, and documentation. Release management involves making decisions on system release dates, preparing all information for distribution, and documenting each system release.

The goals of process improvement are higher product quality, reduced process costs, and faster delivery of software. ■ The principal approaches to process improvement are agile approaches, geared to reducing process overheads, and maturity-based approaches based on better process management and the use of good software engineering practice.

The process improvement cycle involves process measurement, process analysis and modeling, and process change. ■ Process models, which show the activities in a process and their relationships with software products, are used for process description. In practice, however, engineers involved in software development always adapt models to their local circumstances. ■ Measurement should be used to answer specific questions about the software process used. These questions should be based on organizational improvement goals. ■ Three types of process metrics used in the measurement process are time metrics, resource utilization metrics, and event metrics. ■ The CMMI process maturity model is an integrated process improvement model that supports both staged and continuous process improvement. ■ Process improvement in the CMMI model is based on reaching a set of goals related to good software engineering practice and describing, standardizing, and controlling the practices used to achieve these goals. The CMMI model includes recommended practices that may be used, but these are not obligatory.

